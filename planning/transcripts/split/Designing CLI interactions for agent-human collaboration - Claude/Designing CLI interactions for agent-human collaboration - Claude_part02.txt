# Part 2/5
# Lines 201-400 of 892

Scientific rigor in investigations
Accessibility without requiring extensive training
The three approaches should represent different philosophies while meeting all the requirements.
Based on my review of the project documents and research into human-AI interaction patterns, here are three distinct interface approaches that balance simplicity, power, and cultural values:
Option 1: Natural Language First with Progressive Enhancement
"Ask anything, drill deeper when needed"
NaturalLanguageInterface
Primary interaction through conversation, with optional structured commands
Philosophy: Everyone can use it immediately, experts can unlock power features
# Parse intent - is this a question, investigation request, or command?
# "What's happening with product-service?"
INVESTIGATION_REQUEST
# "I've received an SLO alert..."
guided_investigation_mode
# "compass hypothesis add --type database_timeout"
Core Interaction Modes
I've received an SLO alert
I'll investigate the product
Starting scientific analysis
Feature flag deployment at
Feature flag misconfiguration
Checking flag configuration
Database connection exhaustion
Monday pattern matches historical incidents
Analyzing connection pools
What additional context can you provide about recent changes?
Structured Enhancement
Focus on the feature flag issue
Investigate database connections
Check payment service dependencies
Suggest another direction
You can also use commands like
"Payment provider had issues at 14:00"
"Feature flags need gradual rollout"
✅ Zero learning curve - anyone can start immediately
✅ Natural for POs and on-call engineers
✅ Preserves power features without forcing them
✅ Promotes psychological safety (feels like asking a colleague)
✅ Supports Learning Teams through conversational context capture
❌ Natural language ambiguity may require clarification
❌ Power users might find conversation slower initially
❌ Harder to script/automate without structure
❌ Token costs higher for natural language processing
This approach follows research showing that unstructured interviews allow spontaneity and questions to develop during interaction, with open-ended questions enabling respondents to shift direction and bring unanticipated information
. By making conversation the default but allowing structured commands when needed, we accommodate both novice users (POs) and experts without forcing either into an uncomfortable paradigm.
Implementation Complexity:
7/10 (NLP intent classification, context management)
9/10 (natural for everyone, no training required)
6/10 (higher token usage, but can optimize with caching)
9/10 (conversational format promotes open sharing)
Option 2: Visual Investigation Canvas with CLI Companion
"See the investigation unfold, interact how you prefer"
VisualCanvasInterface
Web-based visual investigation map with multiple interaction methods
Philosophy: Make the investigation visible and interactive
<div class="investigation-canvas">
<!-- Visual hypothesis tree showing all paths -->
<div class="hypothesis-tree">
render_hypothesis_nodes
<!-- Current focus area with details -->
<div class="focus-panel">
render_current_hypothesis
<!-- Multiple input methods -->
<div class="interaction-bar">
<input type="text" placeholder="Ask a question or give a command..." />
<button>Quick Actions ▼</button>
Visual Investigation Map
┌─────────────────────────────────────────┐
INVESTIGATING            │
└─────────────────────────────────────────┘
Deployment correlation ████████░░
Connection pools normal
Click nodes to explore
Drag to reprioritize hypotheses
Learning Teams Integration
Suggest based on hypothesis
What have we learned?
• Feature flags need staged rollout ←
• Monday load patterns differ ←
✅ Visual learners can see the entire investigation
✅ Multiple interaction methods suit different preferences
✅ Reduces cognitive load through spatial organization
✅ Natural collaboration (everyone sees same view)
✅ Built-in documentation of investigation path
❌ Requires browser/screen (not pure terminal)
❌ More complex implementation (frontend + backend)
❌ May overwhelm with too much information
❌ Mobile experience would be limited
The design space of human-AI collaboration includes agency, interaction, and adaptation dimensions, with visual representations helping users understand complex system states
. This approach makes the investigation's state visible while supporting multiple interaction paradigms, crucial for maintaining situation awareness during incidents.
8/10 (requires frontend framework, WebSocket for updates)
7/10 (intuitive but needs visual literacy)
5/10 (efficient structured commands, visual state management)
8/10 (transparency promotes learning culture)
Option 3: Adaptive Conversational Agent with Context-Aware Modes
"The interface that learns and adapts to each user and situation"
Dynamically adjusts interaction style based on user, urgency, and context
Philosophy: One interface that works perfectly for everyone
# Learns preferences over time
# Terse, action-focused
# Detailed, scientific
# Reflective, collaborative
# Educational, verbose
'investigations_count'
Drain traffic to region
'll help you investigate this issue. Let me explain what I'
I'm gathering data about the product
Dependencies that might be affected
Explain what I'm seeing
Show you how to investigate yourself
fix the problem quickly
Let's review the product
service incident together
I'll invite them to this review
What made sense at the time?
"We deployed at low-traffic time, seemed safe"
"The flag was tested in staging"
___________________________________
Progressive Revelation
# They know what they're doing
# They need more context
✅ Perfect fit for each user and situation
✅ Reduces cognitive load by adapting to context
✅ Builds user confidence through appropriate guidance
✅ Optimizes for both speed (emergency) and learning
✅ Naturally promotes Learning Teams culture
❌ Complex to implement and test all modes
❌ May be unpredictable (users unsure what to expect)
❌ Requires user profiling and state management
❌ Could be frustrating if mode selection is wrong
Research shows human-AI synergy occurs when systems are redesigned around how humans and AI work together, not just dividing subtasks
. This adaptive approach treats each interaction as unique, optimizing for the specific combination of user expertise, incident severity, and organizational learning needs. The system learns from every interaction, becoming more effective over time.
9/10 (ML for adaptation, complex state management)
8/10 (natural once calibrated, but takes time to learn user)
7/10 (requires profiling, but optimizes token usage over time)
10/10 (explicitly designed for Learning Teams methodology)
Given your goals of accessibility, scientific rigor, and cultural improvement, I recommend
starting with Option 1 (Natural Language First)
Option 3 (Adaptive Agent)
Immediate accessibility
- POs and engineers can use it day one
- Natural language is universal
Progressive enhancement
- Power users aren't limited
- Conversational format naturally promotes psychological safety and learning
- Can add visual canvas and adaptive behaviors as enhancements
Phase 1: Natural language with basic intent recognition
Phase 2: Add structured commands for power users
Phase 3: Introduce visual canvas for complex incidents
Phase 4: Implement adaptive behaviors based on usage patterns
This approach ensures COMPASS remains true to observability principles - allowing engineers to ask questions about their systems while maintaining scientific rigor and promoting a learning culture.
This sounds like a good idea. I like your approach. I really believe me and you can really help many enterprises change their culture with this tool so it's important we make it accessible, friendly and safe for everyone, but still ensure it's open and auditable and clearly captures and records each action taken. The way this information is then presented is also important, but we've covered this in our conversations about post mortems, and we've made an architectureal document for it. Please do the same now for this feature, the interface. Consider everything we've spoken about and referenced, and create a detailed architecture document, which can be referenced from the main architecture document, that Claude Code can use as a complete document to build exactly what we have in mind,
Architected comprehensive interface documentation for enterprise implementation.
The user wants me to create a comprehensive architecture document for the COMPASS human-AI interface system. This needs to be detailed enough for Claude Code to implement, covering all the aspects we've discussed:
Natural language first approach with progressive enhancement
Safety and learning culture considerations from Learning Teams methodology
Audit trail and transparency requirements
Multiple interaction modes (conversational, structured, expert)
Integration with the existing COMPASS architecture
Clear recording of human decisions as first-class entities
Adaptive behaviors over time
I should structure this as a formal architecture document that:
References the existing COMPASS architecture
Provides clear implementation guidance
Includes code examples and data models
Addresses all non-functional requirements (safety, auditability, culture)
Can serve as a standalone reference for implementation
Let me create a comprehensive document that captures everything we've discussed.
COMPASS Human-AI Interface Architecture
This document defines the architecture for COMPASS's human-AI interface system, designed to democratize incident investigation while promoting a learning culture. The interface implements a "Natural Language First" approach with progressive enhancement, enabling both Product Owners and Senior Engineers to effectively investigate incidents without extensive training. Every interaction is auditable, every decision is captured with context, and the system actively promotes psychological safety through Learning Teams methodology.
The interface serves as the primary interaction layer between human operators and COMPASS's multi-agent investigation system, translating natural language queries into scientific investigations while preserving human agency and capturing organizational learning.
"""Non-negotiable principles governing all interface decisions"""
"Anyone can use it without training"
PROGRESSIVE_ENHANCEMENT
"Power grows with expertise, not required from start"
"No blame, focus on learning and improvement"
COMPLETE_AUDITABILITY
"Every action recorded with context and reasoning"
"Humans decide, AI advises and accelerates"
"Actively promotes Learning Teams methodology"
"Hypotheses, evidence, and systematic investigation"
1.2 Learning Teams Integration
Following research showing Learning Teams generate
114% more improvement actions
versus 30% for traditional RCA:
: All relevant staff involved, not just those in the incident
: How work normally happens, not what went wrong
: System improvements, not person-focused actions
1.3 Cognitive Load Management
Based on cognitive load research:
Reduce extraneous load
: Progressive disclosure of information
Manage intrinsic load
: Break complex investigations into clear phases
: Help users build mental models of the system
2. System Architecture
2.1 High-Level Architecture
Primary interface layer for COMPASS
Handles all human-AI interactions with multiple modalities
MultiModalInputProcessor
