
---

# COMPASS: Comprehensive Observability Multi-Agent Platform for Adaptive System Solutions
## Architecture & Implementation Guide - Part 1 of 5

**Version:** 1.0  
**Status:** Design Phase  
**Target:** Production-grade AI-powered incident investigation platform

---

## Executive Summary

COMPASS is an AI-powered incident investigation platform that orchestrates multiple specialized agents following Incident Command System (ICS) principles to rapidly diagnose production incidents. The platform uses OODA loop reasoning (Observe-Orient-Decide-Act) to systematically answer three critical questions: **What** is happening? **Where** is it happening? **Why** is it happening?

Unlike traditional monitoring tools that present raw data, COMPASS generates competing hypotheses, gathers evidence from multiple sources (LGTM stack, code repositories, documentation, configuration), and guides human incident commanders through systematic investigation. The platform learns from each incident, continuously improving its diagnostic capabilities.

**Key Innovation:** Human-AI collaboration where AI accelerates data gathering and pattern recognition while humans provide domain expertise and make critical decisions.

---

## Part 1: Foundational Architecture & OODA Reasoning

### 1.1 Core Design Principles

#### 1.1.1 Safety-First Multi-Agent Design

**Problem:** Autonomous agents can make dangerous decisions in production environments.

**Solution:** Human-in-the-loop architecture with graduated autonomy:

```
Level 0: Data Gathering Only
- Agents query observability systems
- No analysis, just present raw results
- Zero risk of incorrect conclusions

Level 1: Hypothesis Generation (TARGET FOR V1)
- Agents analyze data and propose hypotheses
- Present reasoning and evidence
- Humans select which hypothesis to investigate
- Humans execute all actions

Level 2: Guided Investigation (FUTURE)
- Agents automatically pursue selected hypothesis
- Request additional data as needed
- Humans approve key decision points

Level 3: Autonomous Investigation (DISTANT FUTURE)
- Agents investigate independently for known patterns
- Humans review results
- Emergency stop always available
```

**V1 Implementation:** We implement Level 1 only. All investigation decisions remain with humans. This ensures:
- No risk of AI making incorrect diagnoses
- Humans validate all reasoning
- Natural learning loop (humans see AI logic, improve prompts)
- Regulatory/compliance friendly

#### 1.1.2 OODA Loop as Investigation Framework

The OODA loop (Observe-Orient-Decide-Act) provides the cognitive framework for systematic incident investigation. We adapt it specifically for our multi-agent architecture:

**Traditional OODA Loop:**
```
Observe â†’ Orient â†’ Decide â†’ Act â†’ (feedback loop)
```

**COMPASS OODA Adaptation:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OBSERVE: Multi-Agent Parallel Data Gathering                â”‚
â”‚                                                              â”‚
â”‚ Specialist agents query their domains simultaneously:       â”‚
â”‚ â€¢ Database Agent â†’ Mimir (connection pools, query times)   â”‚
â”‚ â€¢ Network Agent â†’ Mimir (latency, packet loss, DNS)        â”‚
â”‚ â€¢ Application Agent â†’ Loki (errors, warnings, patterns)    â”‚
â”‚ â€¢ Infrastructure Agent â†’ Mimir (CPU, memory, disk)         â”‚
â”‚ â€¢ Observability Agent â†’ Tempo (traces, service graph)      â”‚
â”‚                                                              â”‚
â”‚ Parallel execution compresses observation from 15-20 min    â”‚
â”‚ to under 2 minutes.                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ORIENT: Synthesis & Hypothesis Generation                   â”‚
â”‚                                                              â”‚
â”‚ Orchestrator agent synthesizes observations:                â”‚
â”‚ 1. Identify patterns across domains                         â”‚
â”‚ 2. Correlate timing of events                               â”‚
â”‚ 3. Compare current state to baselines                       â”‚
â”‚ 4. Reference similar past incidents                         â”‚
â”‚ 5. Consider recent changes (code, config, deployment)       â”‚
â”‚                                                              â”‚
â”‚ Generate 3-5 competing hypotheses with:                     â”‚
â”‚ â€¢ Clear description of proposed root cause                  â”‚
â”‚ â€¢ Reasoning based on observed data                          â”‚
â”‚ â€¢ Supporting evidence with citations                        â”‚
â”‚ â€¢ Contradicting evidence (if any)                           â”‚
â”‚ â€¢ What would disprove this hypothesis                       â”‚
â”‚ â€¢ Confidence score (0-100)                                  â”‚
â”‚                                                              â”‚
â”‚ Orientation is where AI adds most value: pattern            â”‚
â”‚ recognition, correlation, historical context.               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DECIDE: Human Selection of Investigation Path               â”‚
â”‚                                                              â”‚
â”‚ Human Incident Commander reviews hypotheses and:            â”‚
â”‚ â€¢ Applies domain expertise and intuition                    â”‚
â”‚ â€¢ Recognizes red herrings from past experience              â”‚
â”‚ â€¢ Considers business context and priorities                 â”‚
â”‚ â€¢ Selects most promising hypothesis to investigate          â”‚
â”‚                                                              â”‚
â”‚ This is where human expertise is irreplaceable.             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ACT: Attempt to Disprove Selected Hypothesis                â”‚
â”‚                                                              â”‚
â”‚ Agents gather additional evidence to test hypothesis:       â”‚
â”‚ â€¢ Query specific metrics that would contradict it           â”‚
â”‚ â€¢ Search logs for counter-examples                          â”‚
â”‚ â€¢ Analyze traces for alternative explanations               â”‚
â”‚ â€¢ Request external data (kubectl, configs, git diffs)       â”‚
â”‚                                                              â”‚
â”‚ Scientific method: actively try to disprove, not confirm.   â”‚
â”‚                                                              â”‚
â”‚ Three outcomes:                                              â”‚
â”‚ 1. DISPROVED: Evidence contradicts hypothesis               â”‚
â”‚    â†’ Return to DECIDE, select next hypothesis               â”‚
â”‚                                                              â”‚
â”‚ 2. NEEDS MORE DATA: Cannot disprove with observability      â”‚
â”‚    â†’ Request human to provide external data                 â”‚
â”‚    â†’ Continue disproof attempts with new data               â”‚
â”‚                                                              â”‚
â”‚ 3. CANNOT DISPROVE: No contradicting evidence found         â”‚
â”‚    â†’ Accept as working theory                               â”‚
â”‚    â†’ Move to next question (Whatâ†’Whereâ†’Why)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
                    (Loop continues)
```

**Critical OODA Principles for COMPASS:**

1. **Speed of iteration** beats perfect analysis
   - Fast OODA loops outperform slow, thorough analysis
   - Our parallel agents compress each loop to minutes, not hours

2. **Getting inside opponent's OODA loop**
   - In incident response, the "opponent" is the incident itself
   - By cycling faster than incident escalation, we stay ahead

3. **Orientation is the pivot point**
   - Most important phase for AI contribution
   - Synthesis of multi-domain observations with historical patterns
   - Humans struggle with parallel processing; AI excels

4. **Feedback is continuous**
   - Each action generates new observations
   - System adapts based on what's discovered
   - Learning system captures successful patterns

#### 1.1.3 Three-Question Investigation Framework

Every incident investigation follows the same progression:

```
WHAT is happening?
â”œâ”€ Symptoms and manifestations
â”œâ”€ Which metrics/logs/traces show anomalies?
â”œâ”€ When did it start?
â”œâ”€ What changed compared to normal?
â””â”€ OUTPUT: Clear description of observable problem

    â†“ (Once WHAT is established)

WHERE is it happening?
â”œâ”€ Which services/components affected?
â”œâ”€ Geographic distribution (if relevant)?
â”œâ”€ Which endpoints/operations impacted?
â”œâ”€ Blast radius: what's affected vs. unaffected?
â””â”€ OUTPUT: Precise scope and boundaries

    â†“ (Once WHERE is established)

WHY is it happening?
â”œâ”€ Root cause analysis
â”œâ”€ Chain of causation
â”œâ”€ Configuration vs. code vs. infrastructure?
â”œâ”€ Recent changes that triggered it?
â””â”€ OUTPUT: Root cause identification
```

**Why This Structure Works:**

1. **Progressive refinement**: Each question narrows the investigation
2. **Prevents premature conclusions**: Forces systematic thinking
3. **Natural checkpoint gates**: Humans verify before proceeding
4. **Maps to incident response phases**: Triage â†’ Diagnosis â†’ Remediation
5. **Enables learning**: Standard structure allows pattern matching

**Agent Behavior Per Question:**

| Question | Agent Focus | Evidence Types | Success Criteria |
|----------|-------------|----------------|------------------|
| **WHAT** | Symptom detection | Error rates, latency, failed requests, log patterns | Clear articulation of observable problem |
| **WHERE** | Boundary analysis | Service topology, traffic patterns, affected endpoints | Precise scope definition |
| **WHY** | Causal analysis | Recent changes, configuration, dependencies, code | Root cause with supporting evidence |

### 1.2 System Architecture Overview

#### 1.2.1 High-Level Component Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Human Incident Commander                     â”‚
â”‚                                                                   â”‚
â”‚  Responsibilities:                                                â”‚
â”‚  â€¢ Receives alerts, initiates investigations                     â”‚
â”‚  â€¢ Reviews agent-generated hypotheses                            â”‚
â”‚  â€¢ Selects investigation paths                                   â”‚
â”‚  â€¢ Provides external data (kubectl, configs)                     â”‚
â”‚  â€¢ Validates conclusions                                         â”‚
â”‚  â€¢ Executes remediation actions                                  â”‚
â”‚  â€¢ Provides feedback for learning                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†• (Web UI)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    COMPASS Platform (Backend)                     â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Investigation State Machine                                â”‚ â”‚
â”‚  â”‚  â€¢ Tracks current question (What/Where/Why)                 â”‚ â”‚
â”‚  â”‚  â€¢ Manages OODA loop progression                            â”‚ â”‚
â”‚  â”‚  â€¢ Stores hypotheses and evidence                           â”‚ â”‚
â”‚  â”‚  â€¢ Coordinates agent activities                             â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                              â†•                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Agent Orchestrator (ICS Command Staff)                     â”‚ â”‚
â”‚  â”‚  â€¢ Spawns specialist agents based on context                â”‚ â”‚
â”‚  â”‚  â€¢ Aggregates findings into hypotheses                      â”‚ â”‚
â”‚  â”‚  â€¢ Routes tool calls to MCP servers                         â”‚ â”‚
â”‚  â”‚  â€¢ Tracks costs and resource usage                          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                              â†•                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  LLM Provider Abstraction Layer                             â”‚ â”‚
â”‚  â”‚  â€¢ Pluggable: OpenAI, Azure OpenAI, Anthropic, Ollama      â”‚ â”‚
â”‚  â”‚  â€¢ Unified interface for all providers                      â”‚ â”‚
â”‚  â”‚  â€¢ Cost calculation and tracking                            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                              â†•                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Learning System                                             â”‚ â”‚
â”‚  â”‚  â€¢ Investigation history store                              â”‚ â”‚
â”‚  â”‚  â€¢ Pattern recognition (vector embeddings)                  â”‚ â”‚
â”‚  â”‚  â€¢ Feedback processing                                      â”‚ â”‚
â”‚  â”‚  â€¢ Query effectiveness tracking                             â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     MCP Gateway & Tool Router                     â”‚
â”‚                                                                   â”‚
â”‚  Routes tool calls to appropriate MCP servers:                   â”‚
â”‚  â€¢ Observability: Grafana MCP, Tempo MCP                        â”‚
â”‚  â€¢ Code: GitHub MCP                                              â”‚
â”‚  â€¢ Documentation: Confluence MCP                                 â”‚
â”‚  â€¢ Configuration: Kubernetes MCP                                 â”‚
â”‚  â€¢ Incidents: PagerDuty/Incident.io MCP                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†•           â†•            â†•            â†•
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Grafana    â”‚   Tempo     â”‚   GitHub     â”‚  Confluence  â”‚
    â”‚  MCP Server â”‚  MCP Server â”‚  MCP Server  â”‚  MCP Server  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†•           â†•            â†•            â†•
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Mimir     â”‚   Tempo     â”‚  Git Repos   â”‚  Wiki/Docs   â”‚
    â”‚   Loki      â”‚   Traces    â”‚  PRs/Issues  â”‚  Runbooks    â”‚
    â”‚   Grafana   â”‚             â”‚              â”‚              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 1.2.2 Agent Hierarchy (ICS-Based)

Following Incident Command System principles, we organize agents hierarchically with clear spans of control:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Orchestrator Agent                        â”‚
â”‚                  (Incident Commander)                        â”‚
â”‚                                                              â”‚
â”‚  Responsibilities:                                           â”‚
â”‚  â€¢ Receives incident context from human                     â”‚
â”‚  â€¢ Spawns 3-5 specialist agents (span of control)          â”‚
â”‚  â€¢ Synthesizes their findings into hypotheses               â”‚
â”‚  â€¢ Presents to human for decision                           â”‚
â”‚  â€¢ Coordinates disproof attempts                            â”‚
â”‚  â€¢ Manages investigation progression (Whatâ†’Whereâ†’Why)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“              â†“              â†“              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Database    â”‚ â”‚  Network     â”‚ â”‚ Application  â”‚ â”‚Infrastructureâ”‚
â”‚  Analyst     â”‚ â”‚  Analyst     â”‚ â”‚ Analyst      â”‚ â”‚ Analyst      â”‚
â”‚  Agent       â”‚ â”‚  Agent       â”‚ â”‚ Agent        â”‚ â”‚ Agent        â”‚
â”‚              â”‚ â”‚              â”‚ â”‚              â”‚ â”‚              â”‚
â”‚ (Section     â”‚ â”‚ (Section     â”‚ â”‚ (Section     â”‚ â”‚ (Section     â”‚
â”‚  Chief)      â”‚ â”‚  Chief)      â”‚ â”‚  Chief)      â”‚ â”‚  Chief)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“              â†“              â†“              â†“
   [MCP Tools]    [MCP Tools]    [MCP Tools]    [MCP Tools]
```

**Span of Control Rules:**
- Orchestrator manages 3-5 analysts maximum (ICS best practice)
- Each analyst can use any MCP tools relevant to their domain
- If >5 domains needed, create manager-level agents who coordinate sub-teams
- Never exceed span of control to prevent coordination failures

**Agent Types:**

**1. Orchestrator Agent (Singular)**
- **Role:** Investigation coordinator, hypothesis synthesizer
- **ICS Equivalent:** Incident Commander
- **Responsibilities:**
  - Parse incident context
  - Determine which specialist agents to spawn
  - Aggregate specialist findings
  - Generate 3-5 competing hypotheses
  - Coordinate disproof attempts
  - Track investigation state and costs

**2. Specialist Analyst Agents (3-5 active per investigation)**

| Agent Type | Domain Focus | Primary MCP Tools | When Spawned |
|------------|--------------|-------------------|--------------|
| **Database Analyst** | SQL databases, connection pools, query performance | `query_prometheus` (DB metrics), `query_loki_logs` (slow queries) | Alert mentions DB, connection errors, query timeouts |
| **Network Analyst** | Latency, packet loss, DNS, load balancers | `query_prometheus` (network metrics), `query_tempo` (network traces) | Timeout errors, DNS issues, cross-region problems |
| **Application Analyst** | Application errors, business logic, endpoints | `query_loki_logs` (application logs), `query_tempo` (request traces), `find_error_pattern_logs` | Error rate alerts, specific endpoint failures |
| **Infrastructure Analyst** | K8s, VMs, resource utilization, scaling | `query_prometheus` (CPU/memory/disk), GitHub MCP (config changes) | Resource exhaustion, pod crashes, OOM kills |
| **Observability Analyst** | Cross-cutting patterns, service dependencies | `query_tempo` (service graph), `find_slow_requests`, GitHub MCP (recent deployments) | Complex incidents requiring correlation |

**3. Role-Based Agents (Spawned for WHY phase)**

| Agent Type | Perspective | Primary Data Sources | Value Added |
|------------|-------------|----------------------|-------------|
| **SRE Agent** | Operational expertise | Historical incidents, runbooks, Confluence docs | Past incident patterns, known failure modes |
| **Developer Agent** | Code-level understanding | GitHub (recent commits, PRs), code documentation | Code changes, feature flag correlations |
| **Architect Agent** | System design | Architecture docs, service dependencies, Confluence | Design limitations, cascading failures |

**Dynamic Spawning Logic:**

```python
def determine_required_agents(incident: Incident) -> List[AgentType]:
    """
    Orchestrator decides which agents to spawn based on incident context
    
    Returns 3-5 agent types to respect span of control
    """
    agents = [AgentType.OBSERVABILITY]  # Always include for correlation
    
    # Parse alert and symptoms
    alert_text = f"{incident.alert_name} {incident.description}".lower()
    
    # Service-specific agents
    if any(keyword in alert_text for keyword in 
           ['database', 'sql', 'connection', 'query', 'timeout']):
        agents.append(AgentType.DATABASE)
    
    if any(keyword in alert_text for keyword in 
           ['latency', 'network', 'dns', 'timeout', 'connection refused']):
        agents.append(AgentType.NETWORK)
    
    if any(keyword in alert_text for keyword in 
           ['error', '500', '4xx', 'exception', 'panic']):
        agents.append(AgentType.APPLICATION)
    
    if any(keyword in alert_text for keyword in 
           ['cpu', 'memory', 'disk', 'pod', 'oom', 'restart']):
        agents.append(AgentType.INFRASTRUCTURE)
    
    # Phase-specific agents
    if incident.current_question == Question.WHY:
        agents.append(AgentType.DEVELOPER)  # Code correlation
        if incident.is_complex:
            agents.append(AgentType.ARCHITECT)  # System design
    
    # Enforce span of control (max 5)
    return agents[:5]
```

### 1.3 OODA Loop Implementation Details

#### 1.3.1 Observe Phase: Parallel Data Gathering

**Objective:** Compress data gathering from 15-20 minutes (human) to under 2 minutes (parallel agents).

**Process:**

```python
@dataclass
class ObservationRequest:
    """What orchestrator asks each analyst to observe"""
    question: Question  # WHAT, WHERE, or WHY
    service_name: str
    alert_details: Dict[str, Any]
    time_window: TimeWindow
    baseline_period: Optional[TimeWindow]  # For comparison
    focus_areas: List[str]  # Specific things to look for

@dataclass
class Observation:
    """What each analyst reports back"""
    agent_type: AgentType
    findings: List[Finding]
    anomalies: List[Anomaly]
    normal_patterns: List[str]  # What's NOT wrong
    confidence: float
    queries_executed: List[Query]
    execution_time_seconds: float

class Finding:
    metric_or_log: str
    current_value: Any
    baseline_value: Optional[Any]
    deviation_percent: Optional[float]
    significance: str  # "critical", "important", "informational"
    timestamp: datetime
    evidence: str  # Raw data or summary
```

**Parallel Execution Pattern:**

```python
async def observe_phase(
    orchestrator: OrchestratorAgent,
    incident: Incident,
    agents: List[AnalystAgent]
) -> List[Observation]:
    """
    All analyst agents observe simultaneously
    """
    # Create observation request
    request = ObservationRequest(
        question=incident.current_question,
        service_name=incident.service,
        alert_details=incident.alert_data,
        time_window=TimeWindow(
            start=incident.start_time - timedelta(minutes=10),
            end=datetime.utcnow()
        ),
        baseline_period=TimeWindow(
            start=incident.start_time - timedelta(days=7, minutes=10),
            end=incident.start_time - timedelta(days=7)
        ),
        focus_areas=orchestrator.extract_focus_areas(incident)
    )
    
    # Launch all agents in parallel
    observation_tasks = [
        agent.observe(request, mcp_gateway)
        for agent in agents
    ]
    
    # Wait for all to complete (with timeout)
    observations = await asyncio.gather(
        *observation_tasks,
        timeout=120,  # 2 minute max
        return_exceptions=True
    )
    
    # Filter out failures
    valid_observations = [
        obs for obs in observations 
        if not isinstance(obs, Exception)
    ]
    
    return valid_observations
```

**Agent-Specific Observation Prompts:**

Each analyst agent receives a specialized prompt for the Observe phase:

**Example: Database Analyst Observe Prompt**

```python
DATABASE_ANALYST_OBSERVE_PROMPT = """
You are a database specialist investigating an incident.

## Context
Service: {service_name}
Alert: {alert_name}
Current Question: {question}
Time Window: {time_window}

## Your Task: OBSERVE Phase
Gather data about database health and performance. Execute queries in parallel where possible.

### Required Observations

1. **Connection Pool Status**
   - Tool: query_prometheus
   - Metrics: database_connection_pool_active, database_connection_pool_max
   - Compare current to baseline: {baseline_period}

2. **Query Performance**
   - Tool: query_loki_logs
   - Search for: slow queries, query timeouts, deadlocks
   - Pattern: {{service="{service_name}"}} |= "slow query" or "timeout" or "deadlock"

3. **Transaction Volume**
   - Tool: query_prometheus
   - Metrics: database_transactions_total, database_rollbacks_total
   - Look for spikes or drops

4. **Database Errors**
   - Tool: query_loki_logs
   - Search for: connection refused, authentication failed, table locks
   - Pattern: {{service="{service_name}"}} |~ "database|sql" |= "error"

5. **Resource Utilization**
   - Tool: query_prometheus
   - Metrics: database_cpu_usage, database_memory_usage
   - Compare to capacity limits

### Output Format
For each observation, report:
- What you measured
- Current value vs baseline
- Whether this is anomalous (yes/no/unclear)
- Significance: critical | important | informational

### Critical Rules
- Execute all queries even if early ones look normal
- Report both anomalies AND normal patterns
- Note if data is missing or tools fail
- Calculate % change from baseline
- No conclusions yet - only observations
"""
```

**Key Observation Principles:**

1. **Comprehensive, not selective**: Don't stop after finding one anomaly
2. **Baseline comparison**: Always compare current to normal
3. **Report negatives**: "Connection pool is healthy" is valuable information
4. **Parallel execution**: Use asyncio to query multiple datasources simultaneously
5. **Structured output**: Consistent format enables orchestrator synthesis

---

**END OF PART 1**

This completes the foundational architecture covering:
- Core design principles (safety-first, OODA framework, three-question structure)
- System architecture overview
- Agent hierarchy following ICS principles
- Observe phase implementation details

# COMPASS: Comprehensive Observability Multi-Agent Platform for Adaptive System Solutions
## Architecture & Implementation Guide - Part 2 of 5



---

## Part 2: Orient Phase (Hypothesis Generation) and Decide Phase (Human Selection)

### 2.1 Orient Phase: Synthesis & Hypothesis Generation

**Objective:** Transform parallel observations into 3-5 competing hypotheses that explain the incident, with clear reasoning and evidence.

**Why This Is The Most Critical Phase:**
- Humans excel at decisions but struggle with parallel data synthesis
- AI excels at pattern recognition across multiple data streams
- This is where historical learning provides maximum value
- Quality of hypotheses determines investigation efficiency

#### 2.1.1 Orchestrator Synthesis Process

The orchestrator receives observations from 3-5 specialist agents and must synthesize them into coherent hypotheses. This is a complex cognitive task that follows a structured process:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ INPUT: Observations from Multiple Agents                     â”‚
â”‚                                                              â”‚
â”‚ Database Agent: Connection pool at 98%, baseline 60%        â”‚
â”‚ Network Agent: No anomalies detected, latency normal        â”‚
â”‚ Application Agent: Error rate +47%, timeouts on /payment   â”‚
â”‚ Infrastructure Agent: CPU/Memory normal, no scaling events  â”‚
â”‚ Observability Agent: Slow traces correlate with DB calls   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: Pattern Recognition                                 â”‚
â”‚                                                              â”‚
â”‚ Orchestrator identifies patterns across observations:       â”‚
â”‚ â€¢ Correlation: Errors coincide with DB connection spikes   â”‚
â”‚ â€¢ Timing: Started at 14:21, deployment was at 14:15       â”‚
â”‚ â€¢ Scope: Only /payment endpoint affected                   â”‚
â”‚ â€¢ Negatives: Network, infrastructure both healthy          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: Historical Context Integration                      â”‚
â”‚                                                              â”‚
â”‚ Query learning system:                                       â”‚
â”‚ â€¢ Similar past incidents (vector search)                    â”‚
â”‚ â€¢ Common failure modes for this service                     â”‚
â”‚ â€¢ Effective diagnostic queries historically                 â”‚
â”‚ â€¢ Recent code/config changes (GitHub MCP)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 3: Hypothesis Generation                               â”‚
â”‚                                                              â”‚
â”‚ Generate competing explanations:                            â”‚
â”‚ â€¢ Each must explain observed symptoms                       â”‚
â”‚ â€¢ Each must align with timing                               â”‚
â”‚ â€¢ Each must account for scope (what's NOT affected)        â”‚
â”‚ â€¢ Each must reference specific evidence                     â”‚
â”‚                                                              â”‚
â”‚ Apply multiple reasoning frameworks:                         â”‚
â”‚ â€¢ First Principles: What could cause these symptoms?       â”‚
â”‚ â€¢ Historical: What has caused this pattern before?         â”‚
â”‚ â€¢ Recent Changes: What changed that could trigger this?    â”‚
â”‚ â€¢ System Design: What design constraints apply?            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 4: Hypothesis Scoring & Ranking                        â”‚
â”‚                                                              â”‚
â”‚ Score each hypothesis on multiple dimensions:               â”‚
â”‚ â€¢ Evidence Quality: Strength of supporting data            â”‚
â”‚ â€¢ Coverage: Does it explain all symptoms?                  â”‚
â”‚ â€¢ Parsimony: Simplest explanation preferred                â”‚
â”‚ â€¢ Plausibility: Consistent with system design              â”‚
â”‚ â€¢ Historical: Similar to past incidents?                   â”‚
â”‚                                                              â”‚
â”‚ Rank hypotheses by composite score                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 5: Falsification Strategy                              â”‚
â”‚                                                              â”‚
â”‚ For each hypothesis, determine:                             â”‚
â”‚ â€¢ What evidence would disprove it?                          â”‚
â”‚ â€¢ What queries would find that evidence?                    â”‚
â”‚ â€¢ What external data is needed?                             â”‚
â”‚                                                              â”‚
â”‚ This enables Act phase (disproof attempts)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OUTPUT: 3-5 Structured Hypotheses                           â”‚
â”‚                                                              â”‚
â”‚ Presented to human for selection                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 2.1.2 Hypothesis Data Structure

Every hypothesis follows a standardized structure to enable consistent presentation, scoring, and disproof:

```python
@dataclass
class Evidence:
    """A single piece of supporting or contradicting evidence"""
    source: str  # "prometheus", "loki", "tempo", "github", "confluence"
    type: str  # "metric", "log", "trace", "code_change", "config"
    description: str
    data: Any  # Raw data or structured summary
    timestamp: Optional[datetime]
    query_used: str  # The exact query that found this
    significance: str  # "strong", "moderate", "weak"
    supports_hypothesis: bool  # True = supports, False = contradicts

@dataclass
class FalsificationStrategy:
    """How to attempt to disprove this hypothesis"""
    description: str  # What we're looking for to disprove
    required_tools: List[str]  # MCP tools needed
    queries: List[str]  # Specific queries to run
    external_data_needed: Optional[str]  # kubectl, config files, etc.
    expected_if_false: str  # What we'd see if hypothesis is wrong

@dataclass
class Hypothesis:
    """A proposed explanation for the incident"""
    id: str  # Unique identifier
    description: str  # One-sentence summary
    detailed_explanation: str  # 2-3 paragraph explanation
    
    # Reasoning
    reasoning_steps: List[str]  # Step-by-step logic
    assumptions: List[str]  # What we're assuming to be true
    
    # Evidence
    supporting_evidence: List[Evidence]
    contradicting_evidence: List[Evidence]
    
    # Scoring
    confidence_score: float  # 0-100, composite of below dimensions
    evidence_quality_score: float  # 0-10
    coverage_score: float  # 0-10, how well it explains all symptoms
    parsimony_score: float  # 0-10, simpler is better
    plausibility_score: float  # 0-10, consistent with system design
    historical_precedent_score: float  # 0-10, seen before?
    
    # Falsification
    falsification_strategy: FalsificationStrategy
    
    # Context
    question_answered: Question  # WHAT, WHERE, or WHY
    generated_by: str  # Agent or reasoning framework
    created_at: datetime
    
    # Tracking
    investigation_attempts: int = 0  # How many times we tried to disprove
    status: str = "proposed"  # proposed, investigating, disproven, accepted

@dataclass 
class HypothesisSet:
    """Collection of competing hypotheses for an incident phase"""
    incident_id: str
    question: Question
    hypotheses: List[Hypothesis]  # Ranked by confidence_score
    generated_at: datetime
    
    # Context that generated these
    observations: List[Observation]
    similar_past_incidents: List[str]  # Incident IDs
    recent_changes: List[Dict]  # Code, config, deployment changes
```

#### 2.1.3 Orchestrator Orient Prompt

The orchestrator uses a carefully structured prompt to synthesize observations into hypotheses. This prompt is critical for quality output:

```python
ORCHESTRATOR_ORIENT_PROMPT = """
You are the Investigation Orchestrator coordinating incident response.

You have received observations from multiple specialist agents. Your task is to synthesize these into 3-5 competing hypotheses that explain the incident.

## Investigation Context

**Current Question:** {question}
- WHAT: Focus on symptoms and manifestations
- WHERE: Focus on scope and boundaries  
- WHY: Focus on root cause

**Service:** {service_name}
**Alert:** {alert_name}
**Started:** {start_time}

## Specialist Agent Observations

{agent_observations}

## Additional Context

### Similar Past Incidents
{similar_incidents}

### Recent Changes (Last 24 Hours)
{recent_changes}

### Service Architecture (from Confluence)
{architecture_summary}

### Common Failure Patterns for This Service
{failure_patterns}

## Your Task: Generate Hypotheses

Create 3-5 distinct hypotheses that could explain the observed symptoms.

### Hypothesis Quality Criteria

1. **Evidence-Based**: Reference specific observations
2. **Comprehensive**: Account for ALL symptoms, not just some
3. **Specific**: Clear, testable explanation (not vague)
4. **Falsifiable**: Include how to disprove it
5. **Diverse**: Cover different possible root causes

### Required Reasoning Frameworks

Apply these frameworks to generate diverse hypotheses:

**Framework 1: Direct Causation**
- What could directly cause the observed symptoms?
- Example: "Connection pool exhausted â†’ timeouts â†’ errors"

**Framework 2: Recent Change Correlation**
- What changed recently that could trigger this?
- Check: deployments, config changes, traffic patterns

**Framework 3: Historical Pattern Matching**
- Have we seen this pattern before?
- What caused it then?

**Framework 4: Cascading Failure**
- Could this be a secondary effect?
- What upstream/downstream issues could cause this?

**Framework 5: Resource Exhaustion**
- Could resource limits be the root cause?
- Consider: connections, memory, file descriptors, rate limits

### For Each Hypothesis Provide

```json
{{
  "id": "hyp-1",
  "description": "One-sentence summary of hypothesis",
  "detailed_explanation": "2-3 paragraph explanation of the proposed root cause, how it would cause observed symptoms, and why timing/scope align",
  
  "reasoning_steps": [
    "Step 1: Observation X suggests Y",
    "Step 2: This aligns with change Z",
    "Step 3: Therefore, likely cause is..."
  ],
  
  "assumptions": [
    "Assuming normal database configuration",
    "Assuming no network issues (confirmed by network agent)"
  ],
  
  "supporting_evidence": [
    {{
      "source": "database_agent",
      "type": "metric", 
      "description": "Connection pool utilization at 98% vs 60% baseline",
      "significance": "strong",
      "query": "database_connection_pool_active{{service='checkout'}}"
    }},
    {{
      "source": "application_agent",
      "type": "log",
      "description": "47% increase in connection timeout errors",
      "significance": "strong",
      "query": "{{service='checkout'}} |= 'connection timeout'"
    }}
  ],
  
  "contradicting_evidence": [
    {{
      "source": "infrastructure_agent",
      "type": "metric",
      "description": "Database CPU at 45%, suggesting DB itself is not overloaded",
      "significance": "moderate"
    }}
  ],
  
  "confidence_score": 78,
  "scores": {{
    "evidence_quality": 8.5,
    "coverage": 9.0,
    "parsimony": 7.0,
    "plausibility": 8.0,
    "historical_precedent": 6.5
  }},
  
  "falsification_strategy": {{
    "description": "To disprove: find evidence that connection pool is adequately sized or that errors occur even when connections are available",
    "queries": [
      "Check connection pool max size configuration",
      "Query for errors when pool utilization was <80%",
      "Check if connection acquisition time correlates with errors"
    ],
    "external_data_needed": "kubectl get configmap database-pool-config -o yaml",
    "expected_if_false": "Would see errors even with low pool utilization, or pool size matches expected load"
  }}
}}
```

### Critical Requirements

1. **Diversity**: Ensure hypotheses represent different root causes, not variations of the same theory

2. **Skepticism**: Include contradicting evidence if it exists. Don't ignore data that doesn't fit.

3. **Specificity**: "Database issue" is too vague. "Connection pool exhausted due to leaked connections from deployment v2.3.1" is specific.

4. **Actionability**: Each hypothesis must be testable with available tools or specified external data.

5. **Ranking**: Order by confidence_score descending. Most likely hypothesis first.

### Common Pitfalls to Avoid

âŒ **Confirmation Bias**: Don't only look for evidence supporting a preconceived notion
âŒ **First Conclusion Trap**: The first explanation that fits isn't always correct
âŒ **Ignoring Negatives**: "Network is healthy" is valuable information
âŒ **Correlation = Causation**: Timing correlation doesn't prove causation
âŒ **Complexity Bias**: Simpler explanations are often correct (Occam's Razor)

### Output Format

Return a JSON array of 3-5 hypotheses, ranked by confidence_score.

Begin your analysis now.
"""
```

#### 2.1.4 Hypothesis Scoring Algorithm

Each hypothesis receives a composite confidence score (0-100) based on multiple dimensions. This scoring must be deterministic and explainable:

```python
class HypothesisScorer:
    """
    Calculates multi-dimensional scores for hypotheses
    
    Composite score balances:
    - Evidence quality (how strong is the supporting data?)
    - Coverage (does it explain all symptoms?)
    - Parsimony (is it the simplest explanation?)
    - Plausibility (consistent with system design?)
    - Historical precedent (seen this before?)
    """
    
    def score_hypothesis(
        self,
        hypothesis: Hypothesis,
        all_observations: List[Observation],
        service_history: ServiceHistory
    ) -> Hypothesis:
        """
        Calculate scores for a hypothesis
        
        Returns hypothesis with populated score fields
        """
        # Score each dimension (0-10)
        evidence_quality = self._score_evidence_quality(hypothesis)
        coverage = self._score_coverage(hypothesis, all_observations)
        parsimony = self._score_parsimony(hypothesis)
        plausibility = self._score_plausibility(hypothesis, service_history)
        historical = self._score_historical_precedent(hypothesis, service_history)
        
        # Composite score with weighted average
        # Evidence and coverage are most important
        composite = (
            evidence_quality * 0.30 +  # 30% weight
            coverage * 0.30 +           # 30% weight
            parsimony * 0.15 +          # 15% weight
            plausibility * 0.15 +       # 15% weight
            historical * 0.10           # 10% weight
        ) * 10  # Scale to 0-100
        
        hypothesis.evidence_quality_score = evidence_quality
        hypothesis.coverage_score = coverage
        hypothesis.parsimony_score = parsimony
        hypothesis.plausibility_score = plausibility
        hypothesis.historical_precedent_score = historical
        hypothesis.confidence_score = composite
        
        return hypothesis
    
    def _score_evidence_quality(self, hypothesis: Hypothesis) -> float:
        """
        Score the quality of supporting evidence
        
        Factors:
        - Number of evidence pieces (more is better, up to a point)
        - Significance of each piece (strong > moderate > weak)
        - Source diversity (metrics + logs + traces > just metrics)
        - Presence of contradicting evidence (reduces score)
        """
        if not hypothesis.supporting_evidence:
            return 0.0
        
        # Count by significance
        strong_evidence = sum(1 for e in hypothesis.supporting_evidence 
                            if e.significance == "strong")
        moderate_evidence = sum(1 for e in hypothesis.supporting_evidence 
                               if e.significance == "moderate")
        weak_evidence = sum(1 for e in hypothesis.supporting_evidence 
                          if e.significance == "weak")
        
        # Weighted sum (strong worth more)
        evidence_strength = (strong_evidence * 3 + 
                           moderate_evidence * 2 + 
                           weak_evidence * 1)
        
        # Diminishing returns after 5 pieces
        evidence_count_score = min(evidence_strength / 10.0, 1.0)
        
        # Source diversity bonus
        unique_sources = len(set(e.source for e in hypothesis.supporting_evidence))
        diversity_bonus = min(unique_sources / 3.0, 0.3)  # Max 0.3 bonus
        
        # Contradiction penalty
        contradiction_penalty = len(hypothesis.contradicting_evidence) * 0.15
        
        score = evidence_count_score + diversity_bonus - contradiction_penalty
        return max(0.0, min(score * 10, 10.0))  # Clamp to 0-10
    
    def _score_coverage(
        self,
        hypothesis: Hypothesis,
        all_observations: List[Observation]
    ) -> float:
        """
        Score how well hypothesis explains all observed symptoms
        
        Does it account for:
        - All anomalies found?
        - Timing of onset?
        - Scope (what's affected vs not affected)?
        """
        # Extract all anomalies from observations
        all_anomalies = []
        for obs in all_observations:
            all_anomalies.extend(obs.anomalies)
        
        if not all_anomalies:
            return 5.0  # Neutral score if no anomalies
        
        # Check how many anomalies are explained by supporting evidence
        explained_anomalies = 0
        for anomaly in all_anomalies:
            for evidence in hypothesis.supporting_evidence:
                if self._evidence_explains_anomaly(evidence, anomaly):
                    explained_anomalies += 1
                    break
        
        coverage_ratio = explained_anomalies / len(all_anomalies)
        
        # Score exponentially - explaining 80%+ is critical
        if coverage_ratio >= 0.9:
            return 10.0
        elif coverage_ratio >= 0.8:
            return 8.5
        elif coverage_ratio >= 0.7:
            return 7.0
        elif coverage_ratio >= 0.5:
            return 5.0
        else:
            return coverage_ratio * 5.0  # Low coverage is bad
    
    def _score_parsimony(self, hypothesis: Hypothesis) -> float:
        """
        Score simplicity (Occam's Razor)
        
        Simpler explanations preferred:
        - Fewer assumptions = higher score
        - Fewer causal steps = higher score
        - Common causes > rare causes
        """
        # Assumption penalty (more assumptions = less parsimonious)
        assumption_penalty = len(hypothesis.assumptions) * 0.5
        
        # Complexity penalty (more reasoning steps = more complex)
        complexity_penalty = max(0, len(hypothesis.reasoning_steps) - 3) * 0.3
        
        # Base score starts at 10
        score = 10.0 - assumption_penalty - complexity_penalty
        
        return max(0.0, min(score, 10.0))
    
    def _score_plausibility(
        self,
        hypothesis: Hypothesis,
        service_history: ServiceHistory
    ) -> float:
        """
        Score whether hypothesis is consistent with system design
        
        Factors:
        - Technically possible given architecture?
        - Aligns with known system constraints?
        - Reasonable given deployment configuration?
        """
        # This is harder to quantify automatically
        # For v1, use a simpler heuristic:
        
        # Check if hypothesis references known system components
        known_components = service_history.get_components()
        hypothesis_text = f"{hypothesis.description} {hypothesis.detailed_explanation}"
        
        references_real_components = any(
            component in hypothesis_text.lower()
            for component in known_components
        )
        
        base_score = 5.0  # Start neutral
        
        if references_real_components:
            base_score += 3.0
        
        # Bonus if hypothesis mentions specific versions, configs, or deployments
        if any(keyword in hypothesis_text.lower() 
               for keyword in ['version', 'config', 'deployment', 'replica']):
            base_score += 2.0
        
        return min(base_score, 10.0)
    
    def _score_historical_precedent(
        self,
        hypothesis: Hypothesis,
        service_history: ServiceHistory
    ) -> float:
        """
        Score based on similarity to past incidents
        
        Higher score if:
        - Similar root cause identified before
        - Same symptom pattern seen before
        - Common failure mode for this service
        """
        # Query similar past incidents
        similar = service_history.find_similar_root_causes(
            hypothesis.description
        )
        
        if not similar:
            return 3.0  # Neutral score if novel
        
        # Score based on how similar and how recent
        similarity_score = similar[0].similarity_score  # 0-1
        recency_weight = 1.0 if similar[0].age_days < 30 else 0.7
        
        score = similarity_score * recency_weight * 10
        
        return min(score, 10.0)
    
    def _evidence_explains_anomaly(
        self,
        evidence: Evidence,
        anomaly: Anomaly
    ) -> bool:
        """
        Check if a piece of evidence directly explains an anomaly
        
        This is a simplified heuristic - in production might use
        semantic similarity or LLM-based matching
        """
        # Check for keyword overlap
        evidence_text = evidence.description.lower()
        anomaly_text = f"{anomaly.metric_or_log} {anomaly.description}".lower()
        
        # Extract key terms
        evidence_terms = set(evidence_text.split())
        anomaly_terms = set(anomaly_text.split())
        
        # High overlap suggests explanation
        overlap = len(evidence_terms & anomaly_terms)
        return overlap >= 2
```

#### 2.1.5 Hypothesis Diversity Enforcement

A critical failure mode is generating 5 variations of the same hypothesis instead of diverse alternatives. The orchestrator must enforce diversity:

```python
class HypothesisDiversityEnforcer:
    """
    Ensures generated hypotheses represent distinct root causes
    
    Problem: LLMs tend to generate variations of their first idea
    Solution: Explicit diversity checks and regeneration
    """
    
    def enforce_diversity(
        self,
        hypotheses: List[Hypothesis],
        min_diversity_score: float = 0.7
    ) -> List[Hypothesis]:
        """
        Check if hypotheses are sufficiently diverse
        
        Returns filtered list or raises NeedRegenerationError
        """
        if len(hypotheses) < 2:
            return hypotheses
        
        # Calculate pairwise diversity
        diversity_matrix = []
        for i, h1 in enumerate(hypotheses):
            for j, h2 in enumerate(hypotheses):
                if i < j:
                    diversity = self._calculate_diversity(h1, h2)
                    diversity_matrix.append((i, j, diversity))
        
        # Check if any pairs are too similar
        similar_pairs = [
            (i, j) for i, j, div in diversity_matrix 
            if div < min_diversity_score
        ]
        
        if similar_pairs:
            # Remove lower-scored hypothesis from similar pairs
            to_remove = set()
            for i, j in similar_pairs:
                if hypotheses[i].confidence_score < hypotheses[j].confidence_score:
                    to_remove.add(i)
                else:
                    to_remove.add(j)
            
            diverse_hypotheses = [
                h for idx, h in enumerate(hypotheses)
                if idx not in to_remove
            ]
            
            # If we removed too many, need to regenerate
            if len(diverse_hypotheses) < 3:
                raise NeedRegenerationError(
                    "Insufficient diversity after filtering. "
                    "Regenerate with explicit diversity constraints."
                )
            
            return diverse_hypotheses
        
        return hypotheses
    
    def _calculate_diversity(
        self,
        h1: Hypothesis,
        h2: Hypothesis
    ) -> float:
        """
        Calculate diversity score between two hypotheses (0-1)
        
        1.0 = completely different
        0.0 = identical
        
        Considers:
        - Different root cause categories
        - Different causal chains
        - Different affected components
        """
        # Check root cause category
        category_overlap = self._categorize_root_cause(h1) == self._categorize_root_cause(h2)
        category_score = 0.0 if category_overlap else 0.4
        
        # Check reasoning similarity (Jaccard similarity of reasoning steps)
        h1_steps = set(" ".join(h1.reasoning_steps).lower().split())
        h2_steps = set(" ".join(h2.reasoning_steps).lower().split())
        
        if h1_steps and h2_steps:
            reasoning_similarity = len(h1_steps & h2_steps) / len(h1_steps | h2_steps)
            reasoning_score = 1.0 - reasoning_similarity
        else:
            reasoning_score = 0.5
        
        # Check affected components
        h1_components = self._extract_components(h1)
        h2_components = self._extract_components(h2)
        
        if h1_components and h2_components:
            component_similarity = len(h1_components & h2_components) / len(h1_components | h2_components)
            component_score = 1.0 - component_similarity
        else:
            component_score = 0.5
        
        # Weighted diversity score
        diversity = (
            category_score * 0.4 +
            reasoning_score * 0.4 +
            component_score * 0.2
        )
        
        return diversity
    
    def _categorize_root_cause(self, hypothesis: Hypothesis) -> str:
        """
        Categorize hypothesis into broad root cause type
        """
        text = f"{hypothesis.description} {hypothesis.detailed_explanation}".lower()
        
        categories = {
            "database": ["database", "sql", "query", "connection pool", "deadlock"],
            "network": ["network", "latency", "timeout", "dns", "packet loss"],
            "code": ["bug", "exception", "panic", "code", "logic error"],
            "configuration": ["config", "misconfiguration", "setting", "parameter"],
            "resource": ["cpu", "memory", "disk", "resource", "exhaustion"],
            "dependency": ["external", "third-party", "downstream", "api"],
            "deployment": ["deployment", "rollout", "release", "version"]
        }
        
        scores = {}
        for category, keywords in categories.items():
            scores[category] = sum(1 for keyword in keywords if keyword in text)
        
        return max(scores.items(), key=lambda x: x[1])[0] if scores else "unknown"
    
    def _extract_components(self, hypothesis: Hypothesis) -> Set[str]:
        """
        Extract system components mentioned in hypothesis
        """
        text = f"{hypothesis.description} {hypothesis.detailed_explanation}".lower()
        
        # Common component keywords
        component_patterns = [
            "database", "cache", "queue", "load balancer", "api gateway",
            "service mesh", "dns", "cdn", "storage", "kubernetes"
        ]
        
        return {comp for comp in component_patterns if comp in text}
```

### 2.2 Decide Phase: Human Selection

**Objective:** Present hypotheses to the human Incident Commander in a format that enables rapid, informed decision-making.

**Key Principle:** The human decides which hypothesis to investigate, not the AI. Human domain expertise and intuition are irreplaceable for navigating ambiguous situations.

#### 2.2.1 Presentation Format

The UI must present hypotheses in a way that:
1. Shows the AI's reasoning clearly
2. Enables quick comparison
3. Surfaces evidence supporting and contradicting
4. Makes the falsification strategy obvious
5. Doesn't overwhelm with information

**Hypothesis Card Design:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ðŸ”µ HYPOTHESIS 1: Database Connection Pool Exhaustion            â”‚
â”‚                                                                  â”‚
â”‚ Confidence: 78% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ (Evidence: 8.5, Coverage: 9.0)      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚ ðŸ“‹ DESCRIPTION                                                   â”‚
â”‚ The connection pool for the payment database is exhausted,      â”‚
â”‚ causing new requests to timeout while waiting for available     â”‚
â”‚ connections. This was triggered by the v2.3.1 deployment which  â”‚
â”‚ introduced a connection leak in the payment processing code.    â”‚
â”‚                                                                  â”‚
â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” â”‚
â”‚                                                                  â”‚
â”‚ ðŸ§  REASONING                                                     â”‚
â”‚ 1. Connection pool utilization jumped to 98% at 14:21          â”‚
â”‚ 2. Error logs show 47% increase in "connection timeout"        â”‚
â”‚ 3. Deployment v2.3.1 occurred at 14:15 (6 min before errors)  â”‚
â”‚ 4. Database CPU normal (45%), ruling out DB overload           â”‚
â”‚ 5. Only /payment endpoint affected (uses payment DB)           â”‚
â”‚                                                                  â”‚
â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” â”‚
â”‚                                                                  â”‚
â”‚ âœ… SUPPORTING EVIDENCE (4 pieces)                               â”‚
â”‚                                                                  â”‚
â”‚ Strong â€¢ Database Agent                                         â”‚
â”‚ Connection pool at 98% utilization vs 60% baseline             â”‚
â”‚ Query: database_connection_pool_active{service="payment"}      â”‚
â”‚ [View Chart â†’]                                                  â”‚
â”‚                                                                  â”‚
â”‚ Strong â€¢ Application Agent                                      â”‚
â”‚ +47% connection timeout errors starting 14:21                  â”‚
â”‚ Pattern: {service="payment"} |= "connection timeout"           â”‚
â”‚ [View Logs â†’]                                                   â”‚
â”‚                                                                  â”‚
â”‚ Moderate â€¢ Observability Agent                                  â”‚
â”‚ Slow traces correlate with DB connection acquisition time      â”‚
â”‚ [View Traces â†’]                                                 â”‚
â”‚                                                                  â”‚
â”‚ Strong â€¢ Developer Agent (GitHub)                               â”‚
â”‚ v2.3.1 modified payment processor connection handling          â”‚
â”‚ Commit: abc123 "Add retry logic to payment processor"          â”‚
â”‚ [View Diff â†’]                                                   â”‚
â”‚                                                                  â”‚
â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” â”‚
â”‚                                                                  â”‚
â”‚ âš ï¸ CONTRADICTING EVIDENCE (1 piece)                            â”‚
â”‚                                                                  â”‚
â”‚ Moderate â€¢ Infrastructure Agent                                 â”‚
â”‚ Database CPU at 45%, suggesting DB itself not overloaded       â”‚
â”‚ Note: This doesn't contradict pool exhaustion on app side      â”‚
â”‚                                                                  â”‚
â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” â”‚
â”‚                                                                  â”‚
â”‚ ðŸ”¬ TO DISPROVE THIS HYPOTHESIS                                  â”‚
â”‚                                                                  â”‚
â”‚ We need to find evidence that:                                  â”‚
â”‚ â€¢ Connection pool is adequately sized for the load, OR         â”‚
â”‚ â€¢ Errors occur even when connections are available, OR         â”‚
â”‚ â€¢ Connection acquisition time doesn't correlate with errors    â”‚
â”‚                                                                  â”‚
â”‚ Required Investigation:                                          â”‚
â”‚ 1. Check connection pool max size configuration                â”‚
â”‚    â†’ Need: kubectl get configmap payment-db-pool -o yaml       â”‚
â”‚                                                                  â”‚
â”‚ 2. Query for errors when pool utilization was <80%            â”‚
â”‚    â†’ Tool: query_prometheus with specific time windows         â”‚
â”‚                                                                  â”‚
â”‚ 3. Analyze if v2.3.1 code actually has connection leak        â”‚
â”‚    â†’ Need: Review code diff for unclosed connections           â”‚
â”‚                                                                  â”‚
â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” â”‚
â”‚                                                                  â”‚
â”‚ ðŸŽ¯ Similar Past Incidents (2 found)                            â”‚
â”‚ â€¢ INC-4521 (30 days ago): Connection pool leak after deploy    â”‚
â”‚   Resolution: Increased pool size + fixed leak in v2.2.4       â”‚
â”‚   [View Incident â†’]                                             â”‚
â”‚                                                                  â”‚
â”‚ â€¢ INC-3892 (90 days ago): Payment DB connection exhaustion     â”‚
â”‚   Resolution: Tuned connection timeout settings                â”‚
â”‚   [View Incident â†’]                                             â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  [ ðŸ” Investigate This Hypothesis ]
```

**Key UI Elements:**

1. **Confidence Bar:** Visual representation of confidence score with dimensional breakdown on hover

2. **Collapsible Sections:** Evidence can expand to show raw data, queries, charts

3. **Evidence Links:** Direct links to Grafana charts, log queries, trace views, git diffs

4. **Similar Incidents:** Links to past investigations with similar patterns

5. **Action Button:** Clear call-to-action to investigate this hypothesis

#### 2.2.2 Human Decision-Making Support

The UI provides tools to help humans make better decisions:

**Comparison View:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HYPOTHESIS COMPARISON                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚          â”‚ Hyp 1:        â”‚ Hyp 2:         â”‚ Hyp 3:             â”‚
â”‚          â”‚ DB Pool       â”‚ Bad Deploy     â”‚ External API       â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ Evidence â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 8.5â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘ 7.2 â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 6.0    â”‚
â”‚ Coverage â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘ 9.0â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 8.0 â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 6.5    â”‚
â”‚ Simplest â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘ 7.0â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘ 9.0 â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘ 4.0    â”‚
â”‚ Historicalâ”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 6.5â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘ 4.0 â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 8.0    â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ Overall  â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘ 78%â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 72% â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 65%    â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ Effort   â”‚ ðŸŸ¢ Easy       â”‚ ðŸŸ¡ Medium      â”‚ ðŸ”´ Hard            â”‚
â”‚ to test  â”‚ Config check  â”‚ Code review    â”‚ External API test  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         [ View Side-by-Side ] [ Show Only Top 2 ]
```

**Filter/Sort Options:**

```
Sort by: âš« Confidence  â—‹ Simplicity  â—‹ Past Success  â—‹ Time to Test

Filter:  â˜‘ Has strong evidence  â˜‘ Seen before  â˜ Easy to test

Show:    â—‹ All (5)  âš« Top 3  â—‹ Top 2
```

**Decision Recording:**

When the human selects a hypothesis to investigate, record their reasoning:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ You selected: Hypothesis 1 (DB Connection Pool Exhaustion)      â”‚
â”‚                                                                  â”‚
â”‚ Optional: Why did you choose this hypothesis?                   â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ The timing matches the deployment exactly, and we've seen   â”‚ â”‚
â”‚ â”‚ connection leaks from this team before. The evidence is     â”‚ â”‚
â”‚ â”‚ strong and it's quick to test.                              â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                  â”‚
â”‚ â˜‘ Store this reasoning to improve future investigations        â”‚
â”‚                                                                  â”‚
â”‚              [ Continue Investigation â†’ ]                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**This feedback feeds the learning system to understand what signals humans find most valuable.**

#### 2.2.3 Handling Edge Cases

**Too Few Hypotheses (1-2):**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âš ï¸  Only 2 hypotheses generated                                 â”‚
â”‚                                                                  â”‚
â”‚ This may indicate:                                               â”‚
â”‚ â€¢ Very clear evidence pointing to one cause                     â”‚
â”‚ â€¢ Limited data available for analysis                           â”‚
â”‚ â€¢ Need for more context                                         â”‚
â”‚                                                                  â”‚
â”‚ Options:                                                         â”‚
â”‚ [ Proceed with available hypotheses ]                           â”‚
â”‚ [ Request additional data sources ]                             â”‚
â”‚ [ Ask AI to generate more diverse alternatives ]                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Too Many Hypotheses (6+):**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ðŸ“Š 6 hypotheses generated                                        â”‚
â”‚                                                                  â”‚
â”‚ Showing top 5 by confidence. Others available if needed.        â”‚
â”‚                                                                  â”‚
â”‚ [ Show all 6 hypotheses ]                                       â”‚
â”‚ [ Let AI consolidate similar ones ]                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**All Low Confidence (<60%):**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âš ï¸  All hypotheses have low confidence                          â”‚
â”‚                                                                  â”‚
â”‚ This suggests we need more information before proceeding.       â”‚
â”‚                                                                  â”‚
â”‚ Recommended next steps:                                          â”‚
â”‚ â€¢ Expand the time window for observation                        â”‚
â”‚ â€¢ Include additional data sources (docs, configs)               â”‚
â”‚ â€¢ Check for similar incidents in history                        â”‚
â”‚ â€¢ Consult team members with domain knowledge                    â”‚
â”‚                                                                  â”‚
â”‚ [ Gather More Data ] [ Proceed Anyway ] [ Escalate ]           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

**END OF PART 2**

This completes the Orient and Decide phases covering:
- Orchestrator synthesis process (5-step pipeline)
- Hypothesis data structures
- Orchestrator Orient prompt engineering
- Multi-dimensional hypothesis scoring
- Diversity enforcement
- Human presentation and decision support
- Edge case handling

---

## Part 3: Act Phase (Disproof Attempts) and Investigation State Management

### 3.1 Act Phase: Systematic Hypothesis Falsification

**Objective:** Actively attempt to disprove the selected hypothesis using the scientific method. Only accept a hypothesis as valid if we cannot find contradicting evidence.

**Core Principle:** We don't try to prove hypotheses correct; we try to prove them wrong. A hypothesis that survives rigorous falsification attempts becomes our working theory.

#### 3.1.1 The Falsification Process

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ INPUT: Human has selected Hypothesis to investigate             â”‚
â”‚                                                                  â”‚
â”‚ Example: "Database connection pool exhaustion"                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: Extract Falsification Strategy                          â”‚
â”‚                                                                  â”‚
â”‚ From hypothesis.falsification_strategy:                         â”‚
â”‚ â€¢ What would disprove this?                                     â”‚
â”‚   - Errors when pool utilization is low                         â”‚
â”‚   - Pool configuration shows adequate sizing                    â”‚
â”‚   - No connection leaks in v2.3.1 code                         â”‚
â”‚                                                                  â”‚
â”‚ â€¢ What queries/tools needed?                                    â”‚
â”‚   - query_prometheus for specific time windows                  â”‚
â”‚   - GitHub MCP for code review                                  â”‚
â”‚   - kubectl for configuration                                   â”‚
â”‚                                                                  â”‚
â”‚ â€¢ What external data required?                                  â”‚
â”‚   - Connection pool configuration (ConfigMap)                   â”‚
â”‚   - Code diff from deployment                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: Execute Automated Disproof Queries                      â”‚
â”‚                                                                  â”‚
â”‚ Agents execute queries that could contradict hypothesis:        â”‚
â”‚                                                                  â”‚
â”‚ Query 1: Find errors during low pool utilization               â”‚
â”‚ Tool: query_prometheus                                           â”‚
â”‚ Logic: If errors exist when utilization <70%, pool size        â”‚
â”‚        is not the bottleneck                                    â”‚
â”‚                                                                  â”‚
â”‚ Query 2: Check connection acquisition timing                    â”‚
â”‚ Tool: query_tempo                                                â”‚
â”‚ Logic: If slow traces don't correlate with pool metrics,       â”‚
â”‚        connection pool is not the cause                         â”‚
â”‚                                                                  â”‚
â”‚ Query 3: Verify deployment timing                              â”‚
â”‚ Tool: GitHub MCP                                                 â”‚
â”‚ Logic: If v2.3.1 deployed hours before incident, less          â”‚
â”‚        likely to be the trigger                                 â”‚
â”‚                                                                  â”‚
â”‚ All queries execute in parallel                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 3: Identify Data Gaps                                      â”‚
â”‚                                                                  â”‚
â”‚ Determine what cannot be checked with observability:            â”‚
â”‚                                                                  â”‚
â”‚ Gap 1: Connection pool max size configuration                   â”‚
â”‚ Type: Kubernetes ConfigMap                                      â”‚
â”‚ Why needed: To verify if pool is undersized                     â”‚
â”‚ Request: kubectl get configmap payment-db-pool -o yaml         â”‚
â”‚                                                                  â”‚
â”‚ Gap 2: Code inspection for connection leaks                     â”‚
â”‚ Type: Code review                                                â”‚
â”‚ Why needed: To confirm leak exists in v2.3.1                   â”‚
â”‚ Request: Review commit abc123 for unclosed connections         â”‚
â”‚                                                                  â”‚
â”‚ Present data gaps to human                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 4: Human Provides External Data                            â”‚
â”‚                                                                  â”‚
â”‚ Human executes commands and pastes results:                     â”‚
â”‚ â€¢ kubectl output                                                 â”‚
â”‚ â€¢ Configuration file contents                                   â”‚
â”‚ â€¢ Manual inspection results                                     â”‚
â”‚                                                                  â”‚
â”‚ System stores this as additional evidence                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 5: Analyze Disproof Attempts                               â”‚
â”‚                                                                  â”‚
â”‚ Orchestrator evaluates all evidence:                            â”‚
â”‚                                                                  â”‚
â”‚ OUTCOME A: DISPROVED                                            â”‚
â”‚ Found contradicting evidence that invalidates hypothesis        â”‚
â”‚ â†’ Mark hypothesis as disproven                                  â”‚
â”‚ â†’ Return to Decide phase, select next hypothesis               â”‚
â”‚                                                                  â”‚
â”‚ OUTCOME B: NEEDS MORE DATA                                      â”‚
â”‚ Cannot disprove with available data                             â”‚
â”‚ â†’ Request additional external data                              â”‚
â”‚ â†’ Loop back to Step 3                                           â”‚
â”‚                                                                  â”‚
â”‚ OUTCOME C: CANNOT DISPROVE                                      â”‚
â”‚ No contradicting evidence found after thorough attempts         â”‚
â”‚ â†’ Accept as working theory for this question                   â”‚
â”‚ â†’ Progress to next question (Whatâ†’Whereâ†’Why)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 3.1.2 Disproof Query Generation

Agents must generate specific, targeted queries that could falsify the hypothesis. This requires inverting the hypothesis logic:

```python
@dataclass
class DisproofQuery:
    """A query designed to find evidence that contradicts hypothesis"""
    description: str  # What we're looking for
    tool_name: str  # MCP tool to use
    query_string: str  # Actual query
    interpretation: str  # How to interpret results
    expected_if_hypothesis_true: str  # What we'd see if hypothesis is correct
    expected_if_hypothesis_false: str  # What we'd see if hypothesis is wrong
    
@dataclass
class DisproofAttempt:
    """Result of attempting to disprove hypothesis"""
    query: DisproofQuery
    result: Any  # Query result
    contradicts_hypothesis: bool  # Did we find contradicting evidence?
    explanation: str  # Why this does/doesn't contradict
    confidence: float  # 0-1, how confident in interpretation

class HypothesisFalsifier:
    """
    Generates and executes queries to attempt hypothesis falsification
    
    Follows Karl Popper's falsification principle:
    A theory is scientific if it's falsifiable
    """
    
    def generate_disproof_queries(
        self,
        hypothesis: Hypothesis,
        available_tools: List[str]
    ) -> List[DisproofQuery]:
        """
        Generate specific queries that could disprove hypothesis
        
        Strategy:
        1. Identify key claims in hypothesis
        2. For each claim, determine what evidence would contradict it
        3. Generate queries to search for that evidence
        """
        queries = []
        
        # Parse hypothesis for testable claims
        claims = self._extract_testable_claims(hypothesis)
        
        for claim in claims:
            # Generate counter-queries
            counter_queries = self._generate_counter_queries(
                claim, 
                available_tools
            )
            queries.extend(counter_queries)
        
        return queries
    
    def _extract_testable_claims(self, hypothesis: Hypothesis) -> List[str]:
        """
        Extract specific, testable claims from hypothesis
        
        Example hypothesis: "Connection pool exhausted due to v2.3.1 leak"
        
        Testable claims:
        1. "Connection pool is at or near capacity"
        2. "Errors correlate with high pool utilization"
        3. "v2.3.1 deployment timing matches incident"
        4. "v2.3.1 code has connection leak"
        """
        # This uses LLM to parse hypothesis into claims
        # For now, simplified extraction from reasoning_steps
        claims = []
        
        for step in hypothesis.reasoning_steps:
            # Each reasoning step is effectively a claim
            claims.append(step)
        
        return claims
    
    def _generate_counter_queries(
        self,
        claim: str,
        available_tools: List[str]
    ) -> List[DisproofQuery]:
        """
        Generate queries that would contradict the claim
        
        Example claim: "Errors correlate with high pool utilization"
        
        Counter-query: "Find errors when pool utilization was <70%"
        Logic: If errors exist at low utilization, pool is not the issue
        """
        queries = []
        
        # Use LLM to generate counter-queries
        # This is a critical reasoning step
        prompt = f"""
Generate disproof queries for this claim:
"{claim}"

For each query, specify:
1. What evidence would contradict this claim?
2. Which tool can find that evidence?
3. What's the exact query?
4. How do we interpret results?

Available tools: {', '.join(available_tools)}

Return as JSON array of disproof queries.
"""
        
        # Execute LLM call to generate queries
        # (Implementation detail - uses LLM provider)
        
        return queries

    async def execute_disproof_attempts(
        self,
        hypothesis: Hypothesis,
        disproof_queries: List[DisproofQuery],
        mcp_gateway: MCPGateway
    ) -> List[DisproofAttempt]:
        """
        Execute all disproof queries and analyze results
        """
        attempts = []
        
        # Execute queries in parallel
        tasks = [
            self._execute_single_query(query, mcp_gateway)
            for query in disproof_queries
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Analyze each result
        for query, result in zip(disproof_queries, results):
            if isinstance(result, Exception):
                # Query failed - cannot use for disproof
                continue
            
            # Interpret result
            attempt = self._interpret_disproof_result(
                query, 
                result, 
                hypothesis
            )
            attempts.append(attempt)
        
        return attempts
    
    def _interpret_disproof_result(
        self,
        query: DisproofQuery,
        result: Any,
        hypothesis: Hypothesis
    ) -> DisproofAttempt:
        """
        Determine if query result contradicts hypothesis
        
        This is a critical reasoning step requiring LLM analysis
        """
        # Use LLM to interpret result against hypothesis
        prompt = f"""
Analyze if this query result contradicts the hypothesis.

Hypothesis: {hypothesis.description}

Query: {query.description}
Expected if hypothesis TRUE: {query.expected_if_hypothesis_true}
Expected if hypothesis FALSE: {query.expected_if_hypothesis_false}

Actual Result:
{self._format_result(result)}

Does this result contradict the hypothesis?
- If yes: Explain how it contradicts
- If no: Explain why it's consistent or inconclusive

Return as JSON:
{{
  "contradicts_hypothesis": true/false,
  "explanation": "...",
  "confidence": 0.0-1.0
}}
"""
        
        # Execute LLM analysis
        # (Returns DisproofAttempt)
        pass

    def evaluate_falsification_outcome(
        self,
        hypothesis: Hypothesis,
        attempts: List[DisproofAttempt]
    ) -> FalsificationOutcome:
        """
        Determine overall outcome of falsification attempts
        
        Returns:
        - DISPROVED: Strong contradicting evidence found
        - NEEDS_MORE_DATA: Cannot test key claims
        - CANNOT_DISPROVE: Survived all tests
        """
        # Check for strong contradictions
        strong_contradictions = [
            a for a in attempts
            if a.contradicts_hypothesis and a.confidence > 0.7
        ]
        
        if strong_contradictions:
            return FalsificationOutcome(
                status=OutcomeStatus.DISPROVED,
                reasoning=self._explain_disproof(strong_contradictions),
                contradicting_attempts=strong_contradictions
            )
        
        # Check for moderate contradictions
        moderate_contradictions = [
            a for a in attempts
            if a.contradicts_hypothesis and a.confidence > 0.5
        ]
        
        if moderate_contradictions:
            # Ambiguous - need more data or human judgment
            return FalsificationOutcome(
                status=OutcomeStatus.AMBIGUOUS,
                reasoning="Found contradicting evidence but not conclusive",
                contradicting_attempts=moderate_contradictions
            )
        
        # Check if we have coverage of all key claims
        tested_all_claims = self._all_claims_tested(hypothesis, attempts)
        
        if not tested_all_claims:
            return FalsificationOutcome(
                status=OutcomeStatus.NEEDS_MORE_DATA,
                reasoning="Cannot test all claims with available data",
                missing_tests=self._identify_missing_tests(hypothesis, attempts)
            )
        
        # No contradictions found after thorough testing
        return FalsificationOutcome(
            status=OutcomeStatus.CANNOT_DISPROVE,
            reasoning="No contradicting evidence found after systematic testing",
            supporting_attempts=attempts
        )
```

#### 3.1.3 External Data Request Management

When observability data is insufficient, we need human-provided external data. This must be managed carefully:

```python
@dataclass
class ExternalDataRequest:
    """Request for data that agents cannot access"""
    id: str
    hypothesis_id: str
    description: str  # Why we need this
    type: str  # "command", "config_file", "code_review", "manual_check"
    
    # For command type
    command: Optional[str]  # Exact command to run
    safe_to_execute: bool  # Whether command is read-only
    
    # For config_file type
    file_path: Optional[str]
    file_type: Optional[str]  # "yaml", "json", "env", etc.
    
    # For code_review type
    repository: Optional[str]
    commit_or_pr: Optional[str]
    review_focus: Optional[str]  # What to look for
    
    # For manual_check type
    instructions: Optional[str]
    expected_findings: Optional[str]
    
    priority: str  # "critical", "important", "optional"
    created_at: datetime
    status: str = "pending"  # pending, provided, skipped

@dataclass
class ExternalDataResponse:
    """Human-provided data in response to request"""
    request_id: str
    provided_at: datetime
    data_type: str  # "text", "json", "yaml", "image"
    content: str  # Raw content
    human_notes: Optional[str]  # Human's interpretation/context

class ExternalDataManager:
    """
    Manages requests for external data and integrates responses
    """
    
    def create_data_requests(
        self,
        hypothesis: Hypothesis,
        falsification_gaps: List[str]
    ) -> List[ExternalDataRequest]:
        """
        Generate specific data requests from identified gaps
        
        Transform abstract gaps into concrete, actionable requests
        """
        requests = []
        
        for gap in falsification_gaps:
            request = self._generate_request_for_gap(gap, hypothesis)
            if request:
                requests.append(request)
        
        return requests
    
    def _generate_request_for_gap(
        self,
        gap: str,
        hypothesis: Hypothesis
    ) -> Optional[ExternalDataRequest]:
        """
        Convert gap description to concrete request
        
        Example gap: "Need connection pool configuration"
        Becomes: kubectl command with exact syntax
        """
        # Use LLM to generate specific request
        prompt = f"""
We need to disprove this hypothesis:
"{hypothesis.description}"

We identified this data gap:
"{gap}"

Generate a specific request for the human Incident Commander.

If it's a command:
- Provide exact command syntax
- Ensure it's read-only (no modifications)
- Explain what we're looking for in the output

If it's a config file:
- Specify exact path
- Explain what values we need to check

If it's code review:
- Specify exact commit/PR
- Explain what pattern we're looking for

Return as JSON:
{{
  "type": "command|config_file|code_review|manual_check",
  "description": "Why we need this",
  ...specific fields based on type...
}}
"""
        
        # Execute LLM call
        # Parse response into ExternalDataRequest
        pass
    
    def present_requests_to_human(
        self,
        requests: List[ExternalDataRequest]
    ) -> str:
        """
        Format requests for UI presentation
        
        Group by priority, provide context, make copy-pasteable
        """
        # Sort by priority
        critical = [r for r in requests if r.priority == "critical"]
        important = [r for r in requests if r.priority == "important"]
        optional = [r for r in requests if r.priority == "optional"]
        
        presentation = []
        
        if critical:
            presentation.append("ðŸ”´ CRITICAL - Required to Continue")
            for req in critical:
                presentation.append(self._format_request(req))
        
        if important:
            presentation.append("\nðŸŸ¡ IMPORTANT - Strongly Recommended")
            for req in important:
                presentation.append(self._format_request(req))
        
        if optional:
            presentation.append("\nðŸŸ¢ OPTIONAL - Would Help but Not Required")
            for req in optional:
                presentation.append(self._format_request(req))
        
        return "\n".join(presentation)
    
    def _format_request(self, request: ExternalDataRequest) -> str:
        """Format individual request for display"""
        
        if request.type == "command":
            return f"""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ {request.description}                                        â”‚
â”‚                                                              â”‚
â”‚ Please run this command:                                     â”‚
â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“ â”‚
â”‚ â”ƒ {request.command}                                        â”ƒ â”‚
â”‚ â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”› â”‚
â”‚                                                              â”‚
â”‚ [Copy Command] [Mark as Done]                               â”‚
â”‚                                                              â”‚
â”‚ Paste output here:                                           â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚                                                          â”‚â”‚
â”‚ â”‚                                                          â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                              â”‚
â”‚ [ Submit ] [ Skip This Request ]                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
"""
        
        elif request.type == "code_review":
            return f"""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ {request.description}                                        â”‚
â”‚                                                              â”‚
â”‚ Repository: {request.repository}                            â”‚
â”‚ Commit/PR: {request.commit_or_pr}                           â”‚
â”‚                                                              â”‚
â”‚ What to look for:                                            â”‚
â”‚ {request.review_focus}                                      â”‚
â”‚                                                              â”‚
â”‚ [View in GitHub] [Mark as Done]                             â”‚
â”‚                                                              â”‚
â”‚ What did you find?                                           â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚                                                          â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                              â”‚
â”‚ [ Submit ] [ Skip This Request ]                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
"""
        
        # Similar formatting for other types...
    
    def integrate_external_data(
        self,
        request: ExternalDataRequest,
        response: ExternalDataResponse,
        hypothesis: Hypothesis
    ) -> Evidence:
        """
        Convert human-provided data into structured evidence
        
        Parse the response and determine if it supports/contradicts hypothesis
        """
        # Parse response based on type
        parsed_data = self._parse_response(response)
        
        # Use LLM to analyze relevance to hypothesis
        prompt = f"""
Analyze this external data in context of hypothesis falsification.

Hypothesis: {hypothesis.description}

Data Request: {request.description}

Human-Provided Data:
{response.content}

Does this data:
1. Support the hypothesis?
2. Contradict the hypothesis?
3. Neither (inconclusive)?

Explain your reasoning and extract key findings.

Return as JSON:
{{
  "interpretation": "supports|contradicts|inconclusive",
  "reasoning": "...",
  "key_findings": [...],
  "confidence": 0.0-1.0
}}
"""
        
        # Execute LLM analysis
        analysis = self._analyze_data(prompt)
        
        # Create Evidence object
        evidence = Evidence(
            source="human_provided",
            type=f"external_{request.type}",
            description=analysis["reasoning"],
            data=parsed_data,
            timestamp=response.provided_at,
            query_used=request.command or request.file_path or "manual",
            significance="strong" if analysis["confidence"] > 0.7 else "moderate",
            supports_hypothesis=(analysis["interpretation"] == "supports")
        )
        
        return evidence
```

#### 3.1.4 OODA Loop Iteration

The Act phase generates new observations, which may trigger another OODA cycle:

```python
class OODALoopController:
    """
    Manages iteration through OODA loops during investigation
    
    A single hypothesis investigation may require multiple OODA cycles:
    - Initial cycle with existing data
    - Additional cycles as new data becomes available
    """
    
    def __init__(self, max_iterations: int = 5):
        self.max_iterations = max_iterations
    
    async def investigate_hypothesis(
        self,
        hypothesis: Hypothesis,
        initial_observations: List[Observation],
        orchestrator: OrchestratorAgent,
        mcp_gateway: MCPGateway
    ) -> InvestigationResult:
        """
        Investigate hypothesis through iterative OODA loops
        
        Loop continues until:
        - Hypothesis is disproved (found contradiction)
        - Hypothesis survives all tests (cannot disprove)
        - Max iterations reached
        - Human decides to stop
        """
        iteration = 0
        all_attempts = []
        pending_data_requests = []
        
        while iteration < self.max_iterations:
            iteration += 1
            
            print(f"OODA Cycle {iteration} for hypothesis: {hypothesis.description}")
            
            # ACT: Generate and execute disproof queries
            disproof_queries = self.generate_disproof_queries(
                hypothesis,
                all_attempts  # Learn from previous attempts
            )
            
            attempts = await self.execute_disproof_attempts(
                hypothesis,
                disproof_queries,
                mcp_gateway
            )
            
            all_attempts.extend(attempts)
            
            # OBSERVE: New observations from disproof attempts
            new_observations = self.extract_observations_from_attempts(attempts)
            
            # Evaluate outcome
            outcome = self.evaluate_falsification_outcome(
                hypothesis,
                all_attempts
            )
            
            if outcome.status == OutcomeStatus.DISPROVED:
                return InvestigationResult(
                    status="disproved",
                    hypothesis=hypothesis,
                    attempts=all_attempts,
                    conclusion=outcome.reasoning,
                    iterations=iteration
                )
            
            elif outcome.status == OutcomeStatus.CANNOT_DISPROVE:
                return InvestigationResult(
                    status="accepted",
                    hypothesis=hypothesis,
                    attempts=all_attempts,
                    conclusion=outcome.reasoning,
                    iterations=iteration
                )
            
            elif outcome.status == OutcomeStatus.NEEDS_MORE_DATA:
                # Generate data requests
                new_requests = self.create_data_requests(
                    hypothesis,
                    outcome.missing_tests
                )
                pending_data_requests.extend(new_requests)
                
                # Present to human
                await self.request_external_data(new_requests)
                
                # Wait for human response
                responses = await self.wait_for_external_data(new_requests)
                
                if not responses:
                    # Human skipped - accept hypothesis tentatively
                    return InvestigationResult(
                        status="accepted_tentatively",
                        hypothesis=hypothesis,
                        attempts=all_attempts,
                        conclusion="Cannot disprove with available data",
                        pending_requests=new_requests,
                        iterations=iteration
                    )
                
                # ORIENT: Integrate new data
                for request, response in zip(new_requests, responses):
                    evidence = self.integrate_external_data(
                        request, 
                        response, 
                        hypothesis
                    )
                    hypothesis.supporting_evidence.append(evidence)
                
                # Loop continues with new data
                continue
            
            elif outcome.status == OutcomeStatus.AMBIGUOUS:
                # Inconclusive - present to human for judgment
                human_decision = await self.request_human_judgment(
                    hypothesis,
                    outcome
                )
                
                if human_decision == "accept":
                    return InvestigationResult(
                        status="accepted_by_human",
                        hypothesis=hypothesis,
                        attempts=all_attempts,
                        conclusion="Human judgment: accepted despite ambiguity",
                        iterations=iteration
                    )
                elif human_decision == "reject":
                    return InvestigationResult(
                        status="rejected_by_human",
                        hypothesis=hypothesis,
                        attempts=all_attempts,
                        conclusion="Human judgment: rejected",
                        iterations=iteration
                    )
                else:  # continue
                    # Human wants more investigation
                    continue
        
        # Max iterations reached
        return InvestigationResult(
            status="max_iterations",
            hypothesis=hypothesis,
            attempts=all_attempts,
            conclusion="Reached maximum investigation iterations",
            iterations=iteration
        )
```

### 3.2 Investigation State Management

The investigation progresses through phases (Whatâ†’Whereâ†’Why) and maintains complex state. This requires careful state machine design.

#### 3.2.1 Investigation State Machine

```python
from enum import Enum
from typing import Optional, List, Dict
from dataclasses import dataclass, field
from datetime import datetime

class Question(Enum):
    """The three questions of incident investigation"""
    WHAT = "what"   # What is happening? (symptoms)
    WHERE = "where"  # Where is it happening? (scope)
    WHY = "why"     # Why is it happening? (root cause)

class PhaseStatus(Enum):
    """Status of investigation phase"""
    NOT_STARTED = "not_started"
    OBSERVING = "observing"
    ORIENTING = "orienting"
    DECIDING = "deciding"  # Human selecting hypothesis
    ACTING = "acting"      # Disproving hypothesis
    COMPLETED = "completed"
    BLOCKED = "blocked"    # Waiting for external data

@dataclass
class InvestigationPhase:
    """State for one phase (What/Where/Why) of investigation"""
    question: Question
    status: PhaseStatus
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    
    # OBSERVE
    observations: List[Observation] = field(default_factory=list)
    active_agents: List[str] = field(default_factory=list)
    
    # ORIENT
    hypotheses: List[Hypothesis] = field(default_factory=list)
    selected_hypothesis: Optional[Hypothesis] = None
    
    # ACT
    disproof_attempts: List[DisproofAttempt] = field(default_factory=list)
    external_data_requests: List[ExternalDataRequest] = field(default_factory=list)
    external_data_responses: List[ExternalDataResponse] = field(default_factory=list)
    
    # RESULT
    accepted_hypothesis: Optional[Hypothesis] = None
    conclusion: Optional[str] = None
    confidence: Optional[float] = None

@dataclass
class Investigation:
    """Complete investigation state across all phases"""
    id: str
    incident_id: str
    service_name: str
    
    # Incident context
    alert_name: str
    alert_description: str
    start_time: datetime
    severity: str
    
    # Investigation metadata
    created_at: datetime
    created_by: str  # User ID
    status: str  # "in_progress", "completed", "abandoned"
    
    # Phases
    what_phase: InvestigationPhase
    where_phase: InvestigationPhase
    why_phase: InvestigationPhase
    current_phase: InvestigationPhase
    
    # Cross-phase data
    service_context: Optional[Dict] = None  # From knowledge sources
    similar_incidents: List[str] = field(default_factory=list)
    recent_changes: List[Dict] = field(default_factory=list)
    
    # Resource tracking
    total_cost_usd: float = 0.0
    llm_calls: int = 0
    tool_calls: int = 0
    duration_minutes: int = 0
    
    # Learning
    feedback: Optional[InvestigationFeedback] = None
    outcome: Optional[InvestigationOutcome] = None

class InvestigationStateMachine:
    """
    Manages investigation progression through phases and states
    
    Enforces valid state transitions and maintains consistency
    """
    
    def __init__(self, investigation: Investigation):
        self.investigation = investigation
        self.state_history: List[tuple[datetime, str]] = []
    
    def start_phase(self, phase: InvestigationPhase):
        """Begin a new investigation phase"""
        if phase.status != PhaseStatus.NOT_STARTED:
            raise InvalidStateTransition(
                f"Cannot start phase that is {phase.status}"
            )
        
        phase.status = PhaseStatus.OBSERVING
        phase.started_at = datetime.utcnow()
        self.investigation.current_phase = phase
        
        self._record_state_change(f"Started {phase.question.value} phase")
    
    def transition_to_orient(self, phase: InvestigationPhase):
        """Move from Observe to Orient"""
        if phase.status != PhaseStatus.OBSERVING:
            raise InvalidStateTransition(
                f"Can only orient from observing, currently {phase.status}"
            )
        
        if not phase.observations:
            raise InvalidStateTransition(
                "Cannot orient without observations"
            )
        
        phase.status = PhaseStatus.ORIENTING
        self._record_state_change(f"Orienting {phase.question.value} phase")
    
    def transition_to_decide(self, phase: InvestigationPhase):
        """Move from Orient to Decide (human selection)"""
        if phase.status != PhaseStatus.ORIENTING:
            raise InvalidStateTransition(
                f"Can only decide from orienting, currently {phase.status}"
            )
        
        if not phase.hypotheses:
            raise InvalidStateTransition(
                "Cannot decide without hypotheses"
            )
        
        if len(phase.hypotheses) < 2:
            print(f"Warning: Only {len(phase.hypotheses)} hypotheses generated")
        
        phase.status = PhaseStatus.DECIDING
        self._record_state_change(f"Awaiting human decision for {phase.question.value}")
    
    def record_human_decision(
        self,
        phase: InvestigationPhase,
        selected_hypothesis: Hypothesis
    ):
        """Record human's hypothesis selection"""
        if phase.status != PhaseStatus.DECIDING:
            raise InvalidStateTransition(
                f"Can only record decision in deciding state, currently {phase.status}"
            )
        
        if selected_hypothesis not in phase.hypotheses:
            raise ValueError("Selected hypothesis not in phase hypotheses")
        
        phase.selected_hypothesis = selected_hypothesis
        phase.status = PhaseStatus.ACTING
        self._record_state_change(
            f"Human selected hypothesis: {selected_hypothesis.description}"
        )
    
    def record_disproof_outcome(
        self,
        phase: InvestigationPhase,
        outcome: FalsificationOutcome
    ):
        """Record result of disproof attempts"""
        if phase.status != PhaseStatus.ACTING:
            raise InvalidStateTransition(
                f"Can only record outcome in acting state, currently {phase.status}"
            )
        
        if outcome.status == OutcomeStatus.DISPROVED:
            # Hypothesis disproved - go back to decide
            phase.status = PhaseStatus.DECIDING
            self._record_state_change("Hypothesis disproved, selecting next")
        
        elif outcome.status == OutcomeStatus.CANNOT_DISPROVE:
            # Hypothesis accepted - phase complete
            phase.accepted_hypothesis = phase.selected_hypothesis
            phase.conclusion = outcome.reasoning
            phase.confidence = phase.selected_hypothesis.confidence_score
            phase.status = PhaseStatus.COMPLETED
            phase.completed_at = datetime.utcnow()
            self._record_state_change(
                f"Completed {phase.question.value}: {phase.conclusion}"
            )
        
        elif outcome.status == OutcomeStatus.NEEDS_MORE_DATA:
            # Block until data provided
            phase.status = PhaseStatus.BLOCKED
            self._record_state_change("Blocked awaiting external data")
    
    def record_external_data(
        self,
        phase: InvestigationPhase,
        response: ExternalDataResponse
    ):
        """Record human-provided external data"""
        if phase.status != PhaseStatus.BLOCKED:
            print(f"Warning: Received data while not blocked (state: {phase.status})")
        
        phase.external_data_responses.append(response)
        
        # Resume acting
        phase.status = PhaseStatus.ACTING
        self._record_state_change("Received external data, resuming disproof")
    
    def progress_to_next_question(self):
        """Move to next question after completing current"""
        current = self.investigation.current_phase
        
        if current.status != PhaseStatus.COMPLETED:
            raise InvalidStateTransition(
                f"Cannot progress with incomplete phase: {current.status}"
            )
        
        if current.question == Question.WHAT:
            self.start_phase(self.investigation.where_phase)
        
        elif current.question == Question.WHERE:
            self.start_phase(self.investigation.why_phase)
        
        elif current.question == Question.WHY:
            # Investigation complete
            self.investigation.status = "completed"
            self._record_state_change("Investigation completed")
    
    def get_progress_summary(self) -> Dict:
        """Get human-readable summary of progress"""
        return {
            "current_question": self.investigation.current_phase.question.value,
            "current_status": self.investigation.current_phase.status.value,
            "what_complete": self.investigation.what_phase.status == PhaseStatus.COMPLETED,
            "where_complete": self.investigation.where_phase.status == PhaseStatus.COMPLETED,
            "why_complete": self.investigation.why_phase.status == PhaseStatus.COMPLETED,
            "what_conclusion": self.investigation.what_phase.conclusion,
            "where_conclusion": self.investigation.where_phase.conclusion,
            "why_conclusion": self.investigation.why_phase.conclusion,
            "duration_minutes": (datetime.utcnow() - self.investigation.created_at).total_seconds() / 60,
            "cost_usd": self.investigation.total_cost_usd
        }
    
    def _record_state_change(self, description: str):
        """Record state transition for audit trail"""
        self.state_history.append((datetime.utcnow(), description))
        print(f"[State Change] {description}")
```

#### 3.2.2 State Persistence

Investigation state must persist across sessions and survive server restarts:

```python
class InvestigationStore:
    """
    Persists investigation state to database
    
    Supports:
    - Resume interrupted investigations
    - Review past investigations
    - Generate investigation reports
    """
    
    def __init__(self, db_connection):
        self.db = db_connection
    
    async def save_investigation(self, investigation: Investigation):
        """Save complete investigation state"""
        # Serialize to JSON
        state = {
            "id": investigation.id,
            "incident_id": investigation.incident_id,
            "service_name": investigation.service_name,
            "status": investigation.status,
            "created_at": investigation.created_at.isoformat(),
            "created_by": investigation.created_by,
            
            # Phases
            "what_phase": self._serialize_phase(investigation.what_phase),
            "where_phase": self._serialize_phase(investigation.where_phase),
            "why_phase": self._serialize_phase(investigation.why_phase),
            "current_phase_question": investigation.current_phase.question.value,
            
            # Context
            "service_context": investigation.service_context,
            "similar_incidents": investigation.similar_incidents,
            "recent_changes": investigation.recent_changes,
            
            # Metrics
            "total_cost_usd": investigation.total_cost_usd,
            "llm_calls": investigation.llm_calls,
            "tool_calls": investigation.tool_calls,
            "duration_minutes": investigation.duration_minutes
        }
        
        await self.db.execute(
            """
            INSERT INTO investigations (id, state, updated_at)
            VALUES ($1, $2, NOW())
            ON CONFLICT (id) 
            DO UPDATE SET state = $2, updated_at = NOW()
            """,
            investigation.id,
            json.dumps(state)
        )
    
    async def load_investigation(self, investigation_id: str) -> Investigation:
        """Load investigation state from database"""
        row = await self.db.fetchrow(
            "SELECT state FROM investigations WHERE id = $1",
            investigation_id
        )
        
        if not row:
            raise InvestigationNotFound(investigation_id)
        
        state = json.loads(row["state"])
        
        # Deserialize
        investigation = Investigation(
            id=state["id"],
            incident_id=state["incident_id"],
            service_name=state["service_name"],
            # ... (deserialize all fields)
        )
        
        return investigation
    
    def _serialize_phase(self, phase: InvestigationPhase) -> Dict:
        """Convert phase to JSON-serializable dict"""
        return {
            "question": phase.question.value,
            "status": phase.status.value,
            "started_at": phase.started_at.isoformat() if phase.started_at else None,
            "completed_at": phase.completed_at.isoformat() if phase.completed_at else None,
            "observations": [self._serialize_observation(o) for o in phase.observations],
            "hypotheses": [self._serialize_hypothesis(h) for h in phase.hypotheses],
            "selected_hypothesis_id": phase.selected_hypothesis.id if phase.selected_hypothesis else None,
            "accepted_hypothesis_id": phase.accepted_hypothesis.id if phase.accepted_hypothesis else None,
            "conclusion": phase.conclusion,
            "confidence": phase.confidence
        }
    
    # Similar serialization methods for other types...
```

#### 3.2.3 Cost Tracking

Every LLM call and tool invocation must be tracked for cost management:

```python
class CostTracker:
    """
    Tracks resource usage and costs across investigation
    
    Per-incident cost tracking enables:
    - Budget enforcement
    - ROI analysis
    - Resource optimization
    """
    
    def __init__(self, investigation: Investigation):
        self.investigation = investigation
        self.cost_breakdown: Dict[str, float] = {}
    
    def record_llm_call(
        self,
        agent_type: str,
        provider: str,
        model: str,
        usage: Dict[str, int],
        cost_usd: float
    ):
        """Record cost of LLM API call"""
        self.investigation.llm_calls += 1
        self.investigation.total_cost_usd += cost_usd
        
        # Track by agent type
        key = f"llm_{agent_type}"
        self.cost_breakdown[key] = self.cost_breakdown.get(key, 0) + cost_usd
        
        # Log details
        print(f"[Cost] {agent_type} LLM call: ${cost_usd:.4f} "
              f"({usage.get('input_tokens', 0)} in, {usage.get('output_tokens', 0)} out)")
    
    def record_tool_call(
        self,
        agent_type: str,
        tool_name: str,
        duration_seconds: float
    ):
        """Record tool invocation (typically free but track for metrics)"""
        self.investigation.tool_calls += 1
        
        # Track tool usage
        key = f"tool_{tool_name}"
        self.cost_breakdown[key] = self.cost_breakdown.get(key, 0) + 1
        
        print(f"[Tool] {agent_type} called {tool_name} ({duration_seconds:.2f}s)")
    
    def check_budget(self, max_cost_usd: float) -> bool:
        """Check if investigation is within budget"""
        return self.investigation.total_cost_usd < max_cost_usd
    
    def get_cost_report(self) -> Dict:
        """Generate cost breakdown report"""
        return {
            "total_cost_usd": self.investigation.total_cost_usd,
            "llm_calls": self.investigation.llm_calls,
            "tool_calls": self.investigation.tool_calls,
            "duration_minutes": self.investigation.duration_minutes,
            "cost_per_minute": (
                self.investigation.total_cost_usd / self.investigation.duration_minutes
                if self.investigation.duration_minutes > 0 else 0
            ),
            "breakdown": self.cost_breakdown
        }
```

---

**END OF PART 3**

This completes the Act phase and investigation state management covering:
- Systematic hypothesis falsification process
- Disproof query generation and execution
- External data request management
- OODA loop iteration logic
- Investigation state machine with phase transitions
- State persistence and recovery
- Cost tracking and budget management


---

## Part 4: Knowledge Integration, Learning System, and Multi-Agent Coordination

### 4.1 Knowledge Integration Architecture

The system must integrate multiple knowledge sources while maintaining context coherence and preventing information overflow.

#### 4.1.1 External Knowledge Sources

```python
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
import asyncio
from enum import Enum
import hashlib

class KnowledgeSourceType(Enum):
    GITHUB = "github"  # Code, issues, PRs, workflows
    CONFLUENCE = "confluence"  # Documentation, runbooks
    SLACK = "slack"  # Team communications, incident history
    PAGERDUTY = "pagerduty"  # Alert history, escalation patterns
    GRAFANA = "grafana"  # Dashboard definitions, annotations
    ELASTICSEARCH = "elasticsearch"  # Log patterns, saved searches
    DATADOG = "datadog"  # Monitor definitions, SLO configs
    INTERNAL_WIKI = "internal_wiki"  # Tribal knowledge
    VENDOR_DOCS = "vendor_docs"  # External documentation

@dataclass
class KnowledgeSource:
    """Represents an external knowledge source"""
    source_type: KnowledgeSourceType
    endpoint: str
    auth_method: str  # "api_key", "oauth", "basic"
    cache_ttl_seconds: int = 3600
    rate_limit: int = 100  # requests per minute
    priority: int = 1  # 1-5, higher = more important
    
class KnowledgeIntegrator:
    """Manages integration with external knowledge sources"""
    
    def __init__(self, mcp_server):
        self.mcp = mcp_server
        self.sources: Dict[KnowledgeSourceType, KnowledgeSource] = {}
        self.cache = {}  # Simple in-memory cache
        self.embeddings_cache = {}  # Vector embeddings for semantic search
        
    async def search_github_for_patterns(
        self,
        error_patterns: List[str],
        service_name: str,
        time_window_days: int = 30
    ) -> Dict[str, Any]:
        """Search GitHub for similar error patterns in code/issues"""
        
        results = {
            "code_matches": [],
            "issue_matches": [],
            "pr_fixes": [],
            "workflow_failures": []
        }
        
        # Search code for error handling patterns
        code_query = f"org:mycompany {service_name} {' OR '.join(error_patterns[:3])}"
        code_results = await self._github_code_search(code_query)
        
        for match in code_results[:5]:
            results["code_matches"].append({
                "file": match["path"],
                "repository": match["repository"]["full_name"],
                "line_numbers": match["line_numbers"],
                "context": match["text_matches"],
                "last_modified": match["last_modified"],
                "relevance_score": self._calculate_relevance(match, error_patterns)
            })
        
        # Search issues for similar problems
        issue_query = f"is:issue {service_name} {error_patterns[0]}"
        issue_results = await self._github_issue_search(issue_query, time_window_days)
        
        for issue in issue_results[:5]:
            results["issue_matches"].append({
                "number": issue["number"],
                "title": issue["title"],
                "state": issue["state"],
                "created_at": issue["created_at"],
                "closed_at": issue.get("closed_at"),
                "resolution": self._extract_resolution(issue),
                "similar_symptoms": self._extract_symptoms(issue["body"]),
                "relevance_score": self._calculate_issue_relevance(issue, error_patterns)
            })
        
        # Find PRs that fixed similar issues
        pr_query = f"is:pr is:merged {service_name} fixes"
        pr_results = await self._github_pr_search(pr_query, time_window_days)
        
        for pr in pr_results[:3]:
            if self._is_relevant_fix(pr, error_patterns):
                results["pr_fixes"].append({
                    "number": pr["number"],
                    "title": pr["title"],
                    "merged_at": pr["merged_at"],
                    "files_changed": pr["changed_files"],
                    "commit_messages": await self._get_pr_commits(pr["number"]),
                    "fix_pattern": self._extract_fix_pattern(pr)
                })
        
        return results
    
    async def search_confluence_runbooks(
        self,
        service_name: str,
        symptoms: List[str]
    ) -> List[Dict]:
        """Search Confluence for relevant runbooks and documentation"""
        
        # Build CQL (Confluence Query Language) query
        cql = f'space="ENGINEERING" AND (title ~ "{service_name}" OR text ~ "{service_name}")'
        
        # Add symptom keywords
        symptom_clause = " OR ".join([f'text ~ "{s}"' for s in symptoms[:3]])
        cql += f' AND ({symptom_clause})'
        
        results = await self._confluence_search(cql)
        
        runbooks = []
        for page in results[:5]:
            content = await self._get_confluence_content(page["id"])
            
            runbook = {
                "title": page["title"],
                "url": page["_links"]["webui"],
                "last_updated": page["version"]["when"],
                "author": page["version"]["by"]["displayName"],
                "relevant_sections": self._extract_relevant_sections(content, symptoms),
                "troubleshooting_steps": self._extract_steps(content),
                "known_issues": self._extract_known_issues(content),
                "contact_points": self._extract_contacts(content)
            }
            
            # Calculate relevance score
            runbook["relevance_score"] = self._calculate_runbook_relevance(
                runbook, service_name, symptoms
            )
            
            runbooks.append(runbook)
        
        return sorted(runbooks, key=lambda x: x["relevance_score"], reverse=True)
    
    async def search_slack_history(
        self,
        channels: List[str],
        keywords: List[str],
        time_window_hours: int = 168  # 1 week
    ) -> Dict[str, List]:
        """Search Slack for relevant discussions about similar incidents"""
        
        results = {
            "incident_discussions": [],
            "resolution_messages": [],
            "expert_mentions": {}
        }
        
        for channel in channels:
            # Search messages in channel
            messages = await self._slack_search(
                channel=channel,
                query=" ".join(keywords[:3]),
                time_window_hours=time_window_hours
            )
            
            # Analyze message threads for incident patterns
            for thread in self._group_into_threads(messages):
                if self._is_incident_discussion(thread):
                    discussion = {
                        "channel": channel,
                        "timestamp": thread[0]["ts"],
                        "participants": list(set([m["user"] for m in thread])),
                        "duration_minutes": self._calculate_thread_duration(thread),
                        "summary": self._summarize_thread(thread),
                        "resolution_found": self._has_resolution(thread),
                        "key_findings": self._extract_findings(thread)
                    }
                    results["incident_discussions"].append(discussion)
                    
                    # Track expert involvement
                    for participant in discussion["participants"]:
                        if participant not in results["expert_mentions"]:
                            results["expert_mentions"][participant] = 0
                        results["expert_mentions"][participant] += 1
        
        # Identify top experts for this type of issue
        results["suggested_experts"] = sorted(
            results["expert_mentions"].items(),
            key=lambda x: x[1],
            reverse=True
        )[:3]
        
        return results

    def _calculate_relevance(self, match: Dict, patterns: List[str]) -> float:
        """Calculate relevance score for code match"""
        score = 0.0
        
        # Check pattern matches
        for pattern in patterns:
            if pattern.lower() in match.get("text_matches", "").lower():
                score += 0.2
        
        # Recent modifications get higher score
        if "last_modified" in match:
            days_old = (datetime.now() - datetime.fromisoformat(match["last_modified"])).days
            score += max(0, (30 - days_old) / 30) * 0.3
        
        # File path relevance
        if "error" in match["path"].lower() or "handler" in match["path"].lower():
            score += 0.2
        
        return min(1.0, score)

```

#### 4.1.2 Knowledge Caching and Indexing

```python
class KnowledgeCache:
    """Intelligent caching system for external knowledge"""
    
    def __init__(self, redis_client=None):
        self.redis = redis_client
        self.memory_cache = {}  # Fast L1 cache
        self.embeddings_store = {}  # Vector embeddings
        self.ttl_map = {}  # TTL per knowledge type
        
    async def get_or_fetch(
        self,
        key: str,
        fetcher_func: callable,
        ttl_seconds: int = 3600,
        use_semantic_search: bool = False
    ):
        """Get from cache or fetch and cache"""
        
        # Check L1 memory cache
        if key in self.memory_cache:
            if self._is_valid(key):
                print(f"[Cache] L1 hit for {key}")
                return self.memory_cache[key]
        
        # Check L2 Redis cache if available
        if self.redis:
            cached = await self.redis.get(key)
            if cached:
                print(f"[Cache] L2 hit for {key}")
                self.memory_cache[key] = json.loads(cached)
                return self.memory_cache[key]
        
        # Fetch fresh data
        print(f"[Cache] Miss for {key}, fetching...")
        data = await fetcher_func()
        
        # Store in both caches
        await self._store(key, data, ttl_seconds)
        
        # Generate embeddings for semantic search if needed
        if use_semantic_search:
            await self._generate_embeddings(key, data)
        
        return data
    
    async def semantic_search(
        self,
        query: str,
        knowledge_type: str,
        top_k: int = 5
    ) -> List[Dict]:
        """Search cached knowledge using semantic similarity"""
        
        query_embedding = await self._get_embedding(query)
        
        results = []
        for key, embeddings in self.embeddings_store.items():
            if knowledge_type in key:
                similarity = self._cosine_similarity(query_embedding, embeddings["vector"])
                if similarity > 0.7:  # Threshold for relevance
                    results.append({
                        "key": key,
                        "similarity": similarity,
                        "content": self.memory_cache.get(key),
                        "metadata": embeddings.get("metadata", {})
                    })
        
        # Sort by similarity and return top K
        results.sort(key=lambda x: x["similarity"], reverse=True)
        return results[:top_k]
    
    async def _generate_embeddings(self, key: str, data: Any):
        """Generate and store embeddings for semantic search"""
        
        # Extract text content based on data type
        text_content = self._extract_text(data)
        
        if text_content:
            # Generate embedding using OpenAI/local model
            embedding = await self._get_embedding(text_content[:8000])  # Token limit
            
            self.embeddings_store[key] = {
                "vector": embedding,
                "metadata": {
                    "generated_at": datetime.now().isoformat(),
                    "content_hash": hashlib.md5(text_content.encode()).hexdigest(),
                    "content_length": len(text_content)
                }
            }

```

### 4.2 Learning System Architecture

The learning system enables the platform to improve over time by capturing patterns, feedback, and outcomes.

#### 4.2.1 Pattern Recognition and Storage

```python
@dataclass
class IncidentPattern:
    """Represents a learned incident pattern"""
    pattern_id: str
    incident_type: str  # "database_deadlock", "memory_leak", etc.
    
    # Pattern characteristics
    symptoms: List[str]  # Observable symptoms
    error_signatures: List[str]  # Specific error messages
    metric_patterns: Dict[str, Any]  # Metric thresholds/patterns
    log_patterns: List[str]  # Log regex patterns
    
    # Resolution data
    root_causes: List[str]  # Historical root causes
    successful_remediations: List[Dict]  # What worked
    failed_attempts: List[Dict]  # What didn't work
    
    # Statistics
    occurrence_count: int = 0
    success_rate: float = 0.0
    avg_resolution_time: float = 0.0
    last_seen: Optional[datetime] = None
    
    # Confidence and validation
    confidence_score: float = 0.0  # 0-1 confidence in pattern
    human_validated: bool = False
    auto_remediate_approved: bool = False

class LearningSystem:
    """Manages pattern learning and recognition"""
    
    def __init__(self, storage_backend):
        self.storage = storage_backend
        self.patterns: Dict[str, IncidentPattern] = {}
        self.active_learning_queue = []
        
    async def learn_from_incident(
        self,
        incident: Investigation,
        resolution: ResolutionReport,
        feedback: HumanFeedback
    ):
        """Learn patterns from completed incident"""
        
        # Extract pattern features
        pattern_features = {
            "symptoms": self._extract_symptoms(incident.observations),
            "error_signatures": self._extract_error_signatures(incident.observations),
            "metric_patterns": self._extract_metric_patterns(incident.observations),
            "log_patterns": self._extract_log_patterns(incident.observations)
        }
        
        # Check if this matches existing pattern
        matched_pattern = await self._match_existing_pattern(pattern_features)
        
        if matched_pattern:
            # Update existing pattern
            await self._update_pattern(
                matched_pattern,
                incident,
                resolution,
                feedback
            )
        else:
            # Create new pattern if sufficiently unique
            if self._is_novel_pattern(pattern_features):
                new_pattern = await self._create_pattern(
                    pattern_features,
                    incident,
                    resolution,
                    feedback
                )
                self.patterns[new_pattern.pattern_id] = new_pattern
                
                # Add to active learning queue for validation
                self.active_learning_queue.append(new_pattern.pattern_id)
        
        # Update pattern confidence scores
        await self._recalculate_confidence_scores()
    
    async def suggest_from_patterns(
        self,
        observations: List[Observation]
    ) -> List[PatternMatch]:
        """Suggest hypotheses based on learned patterns"""
        
        matches = []
        
        for pattern_id, pattern in self.patterns.items():
            match_score = self._calculate_match_score(observations, pattern)
            
            if match_score > 0.6:  # Threshold for suggestion
                matches.append(PatternMatch(
                    pattern=pattern,
                    match_score=match_score,
                    suggested_hypothesis=self._generate_hypothesis(pattern),
                    suggested_actions=self._generate_actions(pattern),
                    confidence=pattern.confidence_score * match_score
                ))
        
        # Sort by confidence
        matches.sort(key=lambda x: x.confidence, reverse=True)
        
        return matches[:5]  # Top 5 pattern matches
    
    async def _update_pattern(
        self,
        pattern: IncidentPattern,
        incident: Investigation,
        resolution: ResolutionReport,
        feedback: HumanFeedback
    ):
        """Update pattern with new incident data"""
        
        # Update occurrence statistics
        pattern.occurrence_count += 1
        pattern.last_seen = datetime.now()
        
        # Update resolution data
        if resolution.success:
            pattern.successful_remediations.append({
                "incident_id": incident.incident_id,
                "actions": resolution.actions_taken,
                "duration_minutes": resolution.duration_minutes,
                "notes": resolution.notes
            })
            
            # Update success rate
            total_attempts = (
                len(pattern.successful_remediations) + 
                len(pattern.failed_attempts)
            )
            pattern.success_rate = len(pattern.successful_remediations) / total_attempts
        else:
            pattern.failed_attempts.append({
                "incident_id": incident.incident_id,
                "actions": resolution.actions_taken,
                "failure_reason": resolution.failure_reason
            })
        
        # Update average resolution time
        successful_times = [
            r["duration_minutes"] 
            for r in pattern.successful_remediations
        ]
        if successful_times:
            pattern.avg_resolution_time = sum(successful_times) / len(successful_times)
        
        # Update confidence based on feedback
        if feedback.accuracy_rating:
            # Exponential moving average for confidence
            alpha = 0.2  # Learning rate
            pattern.confidence_score = (
                alpha * (feedback.accuracy_rating / 5.0) + 
                (1 - alpha) * pattern.confidence_score
            )
        
        # Check for human validation
        if feedback.validated_by_human:
            pattern.human_validated = True
        
        # Store updated pattern
        await self.storage.update_pattern(pattern)

```

#### 4.2.2 Feedback Integration

```python
@dataclass
class HumanFeedback:
    """Captures human feedback on investigation"""
    incident_id: str
    investigator_id: str
    
    # Quality ratings (1-5)
    accuracy_rating: Optional[int] = None
    completeness_rating: Optional[int] = None
    usefulness_rating: Optional[int] = None
    
    # Specific feedback
    correct_hypotheses: List[str] = field(default_factory=list)
    incorrect_hypotheses: List[str] = field(default_factory=list)
    missed_clues: List[str] = field(default_factory=list)
    
    # Resolution feedback
    actual_root_cause: Optional[str] = None
    actual_fix_applied: Optional[str] = None
    time_saved_estimate: Optional[float] = None
    
    # Validation flags
    validated_by_human: bool = False
    approved_for_automation: bool = False
    
    # Additional notes
    notes: Optional[str] = None
    timestamp: datetime = field(default_factory=datetime.now)

class FeedbackProcessor:
    """Processes and integrates human feedback"""
    
    def __init__(self, learning_system: LearningSystem):
        self.learning_system = learning_system
        self.feedback_store = []
        
    async def process_feedback(
        self,
        feedback: HumanFeedback,
        investigation: Investigation
    ):
        """Process feedback and update learning system"""
        
        # Store feedback
        self.feedback_store.append(feedback)
        
        # Update hypothesis accuracy tracking
        await self._update_hypothesis_accuracy(feedback, investigation)
        
        # Update agent performance metrics
        await self._update_agent_performance(feedback, investigation)
        
        # Identify systematic issues
        systematic_issues = await self._identify_systematic_issues(feedback)
        if systematic_issues:
            await self._create_improvement_tasks(systematic_issues)
        
        # Update automation approval status
        if feedback.approved_for_automation:
            await self._update_automation_eligibility(
                investigation.incident_type,
                feedback
            )
        
        # Trigger retraining if needed
        if await self._should_trigger_retraining():
            await self._initiate_retraining()
    
    async def _update_hypothesis_accuracy(
        self,
        feedback: HumanFeedback,
        investigation: Investigation
    ):
        """Track hypothesis accuracy over time"""
        
        for hypothesis in investigation.hypotheses:
            if hypothesis.id in feedback.correct_hypotheses:
                await self._record_hypothesis_result(
                    hypothesis_type=hypothesis.category,
                    agent_type=hypothesis.generated_by,
                    correct=True,
                    confidence=hypothesis.confidence
                )
            elif hypothesis.id in feedback.incorrect_hypotheses:
                await self._record_hypothesis_result(
                    hypothesis_type=hypothesis.category,
                    agent_type=hypothesis.generated_by,
                    correct=False,
                    confidence=hypothesis.confidence
                )
    
    async def _identify_systematic_issues(
        self,
        feedback: HumanFeedback
    ) -> List[Dict]:
        """Identify patterns in feedback indicating systematic issues"""
        
        issues = []
        
        # Check recent feedback for patterns
        recent_feedback = self._get_recent_feedback(days=7)
        
        # Pattern: Consistently missing certain types of clues
        missed_clue_patterns = self._analyze_missed_clues(recent_feedback)
        if missed_clue_patterns:
            issues.append({
                "type": "missed_clue_pattern",
                "description": f"Consistently missing: {missed_clue_patterns}",
                "frequency": len(missed_clue_patterns),
                "suggested_action": "Add specialized agent or improve prompts"
            })
        
        # Pattern: Low accuracy for specific incident types
        low_accuracy_types = self._find_low_accuracy_types(recent_feedback)
        for incident_type, accuracy in low_accuracy_types:
            if accuracy < 0.6:  # Less than 60% accuracy
                issues.append({
                    "type": "low_accuracy",
                    "incident_type": incident_type,
                    "current_accuracy": accuracy,
                    "suggested_action": "Retrain models or adjust patterns"
                })
        
        return issues

```

### 4.3 Multi-Agent Coordination Patterns

Implementing robust coordination patterns that handle failures, conflicts, and complex interactions.

#### 4.3.1 Coordination Protocols

```python
class CoordinationProtocol(Enum):
    """Agent coordination strategies"""
    HIERARCHICAL = "hierarchical"  # Strict command chain
    PEER_TO_PEER = "peer_to_peer"  # Direct agent communication
    BLACKBOARD = "blackboard"  # Shared workspace
    MARKET_BASED = "market_based"  # Auction/bidding for tasks
    STIGMERGIC = "stigmergic"  # Indirect coordination via environment

class AgentCoordinator:
    """Manages multi-agent coordination"""
    
    def __init__(self, protocol: CoordinationProtocol):
        self.protocol = protocol
        self.agents: Dict[str, BaseAgent] = {}
        self.task_queue = asyncio.Queue()
        self.blackboard = {}  # Shared state
        self.communication_bus = AsyncMessageBus()
        
    async def coordinate_investigation(
        self,
        incident: Incident,
        available_agents: List[BaseAgent]
    ) -> Investigation:
        """Coordinate multi-agent investigation"""
        
        if self.protocol == CoordinationProtocol.HIERARCHICAL:
            return await self._hierarchical_coordination(incident, available_agents)
        elif self.protocol == CoordinationProtocol.BLACKBOARD:
            return await self._blackboard_coordination(incident, available_agents)
        elif self.protocol == CoordinationProtocol.MARKET_BASED:
            return await self._market_coordination(incident, available_agents)
    
    async def _hierarchical_coordination(
        self,
        incident: Incident,
        agents: List[BaseAgent]
    ) -> Investigation:
        """ICS-style hierarchical coordination"""
        
        # Create command structure
        orchestrator = self._select_orchestrator(agents)
        managers = self._select_managers(agents, max_count=5)
        workers = [a for a in agents if a not in [orchestrator] + managers]
        
        # Initialize investigation
        investigation = Investigation(
            incident_id=incident.id,
            started_at=datetime.now()
        )
        
        # Orchestrator creates investigation plan
        plan = await orchestrator.create_investigation_plan(incident)
        
        # Distribute tasks to managers
        manager_tasks = []
        for manager, task_group in zip(managers, plan.task_groups):
            # Manager coordinates workers for their task group
            task = asyncio.create_task(
                self._manager_coordinate_workers(
                    manager=manager,
                    workers=self._assign_workers(workers, task_group),
                    task_group=task_group,
                    investigation=investigation
                )
            )
            manager_tasks.append(task)
        
        # Wait for all managers to complete
        manager_results = await asyncio.gather(*manager_tasks)
        
        # Orchestrator synthesizes results
        investigation = await orchestrator.synthesize_results(
            manager_results,
            investigation
        )
        
        return investigation
    
    async def _blackboard_coordination(
        self,
        incident: Incident,
        agents: List[BaseAgent]
    ) -> Investigation:
        """Blackboard pattern - shared workspace coordination"""
        
        # Initialize blackboard with incident data
        self.blackboard = {
            "incident": incident,
            "observations": [],
            "hypotheses": [],
            "evidence": {},
            "tasks": [],
            "agent_claims": {}  # Which agent is working on what
        }
        
        # Agents independently observe blackboard and contribute
        agent_tasks = []
        for agent in agents:
            task = asyncio.create_task(
                self._agent_blackboard_loop(agent)
            )
            agent_tasks.append(task)
        
        # Run until convergence or timeout
        try:
            await asyncio.wait_for(
                self._wait_for_convergence(),
                timeout=300  # 5 minutes max
            )
        except asyncio.TimeoutError:
            print("[Coordinator] Investigation timeout, gathering results")
        
        # Cancel agent tasks
        for task in agent_tasks:
            task.cancel()
        
        # Build investigation from blackboard
        return self._build_investigation_from_blackboard()
    
    async def _market_coordination(
        self,
        incident: Incident,
        agents: List[BaseAgent]
    ) -> Investigation:
        """Market-based coordination with task bidding"""
        
        # Create task market
        tasks = self._decompose_incident_to_tasks(incident)
        market = TaskMarket(budget=100.0)  # Token budget
        
        # Agents bid on tasks
        for task in tasks:
            bids = []
            for agent in agents:
                if agent.can_handle(task):
                    bid = await agent.bid_on_task(task)
                    bids.append((agent, bid))
            
            # Award task to best bidder
            if bids:
                winner, winning_bid = min(bids, key=lambda x: x[1].cost)
                market.award_task(task, winner, winning_bid)
        
        # Execute awarded tasks in parallel
        execution_tasks = []
        for task, (agent, bid) in market.awarded_tasks.items():
            execution_tasks.append(
                asyncio.create_task(agent.execute_task(task))
            )
        
        results = await asyncio.gather(*execution_tasks)
        
        # Build investigation from task results
        return self._build_investigation_from_tasks(results)
    
    async def _manager_coordinate_workers(
        self,
        manager: BaseAgent,
        workers: List[BaseAgent],
        task_group: TaskGroup,
        investigation: Investigation
    ):
        """Manager coordinates workers for a task group"""
        
        # Manager decomposes task group
        subtasks = await manager.decompose_tasks(task_group)
        
        # Assign subtasks to workers
        worker_assignments = []
        for subtask, worker in zip(subtasks, workers):
            worker_assignments.append(
                asyncio.create_task(worker.execute_task(subtask))
            )
        
        # Monitor progress with timeout per worker
        results = []
        for assignment in worker_assignments:
            try:
                result = await asyncio.wait_for(assignment, timeout=60)
                results.append(result)
            except asyncio.TimeoutError:
                print(f"[Manager] Worker timeout on task")
                results.append(None)
        
        # Manager synthesizes worker results
        synthesis = await manager.synthesize_worker_results(results)
        
        # Update investigation
        async with investigation.lock:
            investigation.observations.extend(synthesis.observations)
            investigation.evidence.update(synthesis.evidence)
        
        return synthesis

```

#### 4.3.2 Agent Communication Patterns

```python
class MessageType(Enum):
    """Types of inter-agent messages"""
    TASK_REQUEST = "task_request"
    TASK_RESPONSE = "task_response"
    INFORMATION_SHARE = "info_share"
    HELP_REQUEST = "help_request"
    STATUS_UPDATE = "status_update"
    COORDINATION = "coordination"

@dataclass
class AgentMessage:
    """Inter-agent communication message"""
    message_id: str
    sender_id: str
    recipient_id: Optional[str]  # None for broadcast
    message_type: MessageType
    content: Dict[str, Any]
    priority: int = 1  # 1-5, higher is more important
    timestamp: datetime = field(default_factory=datetime.now)
    requires_response: bool = False
    correlation_id: Optional[str] = None  # For request-response

class AsyncMessageBus:
    """Asynchronous message bus for agent communication"""
    
    def __init__(self):
        self.subscribers: Dict[str, List[Callable]] = {}
        self.message_history: List[AgentMessage] = []
        self.pending_responses: Dict[str, asyncio.Future] = {}
        
    async def publish(self, message: AgentMessage):
        """Publish message to bus"""
        
        # Store in history
        self.message_history.append(message)
        
        # Route to recipient(s)
        if message.recipient_id:
            # Direct message
            if message.recipient_id in self.subscribers:
                for handler in self.subscribers[message.recipient_id]:
                    asyncio.create_task(handler(message))
        else:
            # Broadcast
            for recipient_id, handlers in self.subscribers.items():
                if recipient_id != message.sender_id:  # Don't send to self
                    for handler in handlers:
                        asyncio.create_task(handler(message))
        
        # Handle request-response pattern
        if message.requires_response:
            future = asyncio.Future()
            self.pending_responses[message.message_id] = future
            return await future
    
    def subscribe(self, agent_id: str, handler: Callable):
        """Subscribe agent to messages"""
        if agent_id not in self.subscribers:
            self.subscribers[agent_id] = []
        self.subscribers[agent_id].append(handler)
    
    async def respond(self, original_message_id: str, response: Any):
        """Send response to a request message"""
        if original_message_id in self.pending_responses:
            self.pending_responses[original_message_id].set_result(response)

class AgentCommunicationMixin:
    """Mixin for agents to handle communication"""
    
    def __init__(self, agent_id: str, message_bus: AsyncMessageBus):
        self.agent_id = agent_id
        self.message_bus = message_bus
        self.message_bus.subscribe(agent_id, self.handle_message)
        
    async def handle_message(self, message: AgentMessage):
        """Handle incoming message"""
        
        if message.message_type == MessageType.TASK_REQUEST:
            await self._handle_task_request(message)
        elif message.message_type == MessageType.INFORMATION_SHARE:
            await self._handle_information_share(message)
        elif message.message_type == MessageType.HELP_REQUEST:
            await self._handle_help_request(message)
        elif message.message_type == MessageType.STATUS_UPDATE:
            await self._handle_status_update(message)
    
    async def request_help(
        self,
        problem_description: str,
        required_expertise: List[str]
    ) -> List[Dict]:
        """Request help from other agents"""
        
        message = AgentMessage(
            message_id=str(uuid.uuid4()),
            sender_id=self.agent_id,
            recipient_id=None,  # Broadcast
            message_type=MessageType.HELP_REQUEST,
            content={
                "problem": problem_description,
                "required_expertise": required_expertise,
                "context": self.get_current_context()
            },
            priority=3,
            requires_response=True
        )
        
        # Wait for responses with timeout
        try:
            responses = await asyncio.wait_for(
                self.message_bus.publish(message),
                timeout=10
            )
            return responses
        except asyncio.TimeoutError:
            print(f"[{self.agent_id}] No help received in time")
            return []
    
    async def share_finding(
        self,
        finding_type: str,
        data: Any,
        confidence: float
    ):
        """Share finding with other agents"""
        
        message = AgentMessage(
            message_id=str(uuid.uuid4()),
            sender_id=self.agent_id,
            recipient_id=None,  # Broadcast
            message_type=MessageType.INFORMATION_SHARE,
            content={
                "finding_type": finding_type,
                "data": data,
                "confidence": confidence,
                "timestamp": datetime.now().isoformat()
            },
            priority=2
        )
        
        await self.message_bus.publish(message)

```

### 4.4 Handling Failures and Edge Cases

Robust error handling and graceful degradation are critical for production systems.

#### 4.4.1 Failure Detection and Recovery

```python
class AgentFailureHandler:
    """Handles agent failures and recovery"""
    
    def __init__(self):
        self.failure_history: Dict[str, List[FailureRecord]] = {}
        self.circuit_breakers: Dict[str, CircuitBreaker] = {}
        self.recovery_strategies: Dict[str, RecoveryStrategy] = {}
        
    async def handle_agent_failure(
        self,
        agent_id: str,
        task: Task,
        error: Exception
    ) -> RecoveryAction:
        """Handle agent failure with appropriate recovery"""
        
        # Record failure
        self._record_failure(agent_id, task, error)
        
        # Check circuit breaker
        if agent_id not in self.circuit_breakers:
            self.circuit_breakers[agent_id] = CircuitBreaker(
                failure_threshold=3,
                recovery_timeout=60
            )
        
        breaker = self.circuit_breakers[agent_id]
        
        if breaker.is_open():
            # Circuit is open, don't retry with this agent
            return await self._find_alternative_agent(task)
        
        # Determine failure type and recovery strategy
        failure_type = self._classify_failure(error)
        
        if failure_type == FailureType.TRANSIENT:
            # Retry with exponential backoff
            return RecoveryAction(
                action_type="retry",
                agent_id=agent_id,
                task=task,
                delay_seconds=self._calculate_backoff(agent_id)
            )
        
        elif failure_type == FailureType.RESOURCE_EXHAUSTION:
            # Scale down or wait
            return RecoveryAction(
                action_type="throttle",
                agent_id=agent_id,
                task=self._simplify_task(task),
                delay_seconds=30
            )
        
        elif failure_type == FailureType.CAPABILITY_GAP:
            # Find different agent type
            return await self._find_capable_agent(task)
        
        else:  # PERMANENT failure
            # Mark agent as failed and find alternative
            breaker.record_failure()
            return await self._failover_to_backup(task)
    
    def _classify_failure(self, error: Exception) -> FailureType:
        """Classify failure type from error"""
        
        error_msg = str(error).lower()
        
        if any(x in error_msg for x in ["timeout", "connection", "network"]):
            return FailureType.TRANSIENT
        elif any(x in error_msg for x in ["rate limit", "quota", "token"]):
            return FailureType.RESOURCE_EXHAUSTION
        elif any(x in error_msg for x in ["not supported", "unknown tool", "cannot"]):
            return FailureType.CAPABILITY_GAP
        else:
            return FailureType.PERMANENT
    
    async def _find_alternative_agent(self, task: Task) -> RecoveryAction:
        """Find alternative agent for task"""
        
        # Get list of available agents
        available_agents = await self.agent_registry.get_available_agents()
        
        # Filter by capability
        capable_agents = [
            a for a in available_agents
            if a.can_handle(task) and not self.circuit_breakers.get(a.id, CircuitBreaker()).is_open()
        ]
        
        if capable_agents:
            # Select best alternative
            selected = self._select_best_agent(capable_agents, task)
            return RecoveryAction(
                action_type="reassign",
                agent_id=selected.id,
                task=task
            )
        else:
            # No alternatives, degrade gracefully
            return RecoveryAction(
                action_type="degrade",
                task=self._create_degraded_task(task)
            )

class CircuitBreaker:
    """Circuit breaker pattern for agent failures"""
    
    def __init__(self, failure_threshold: int = 3, recovery_timeout: int = 60):
        self.failure_threshold = failure_threshold
        self.recovery_timeout = recovery_timeout
        self.failure_count = 0
        self.last_failure_time = None
        self.state = "closed"  # closed, open, half-open
        
    def is_open(self) -> bool:
        """Check if circuit is open"""
        
        if self.state == "open":
            # Check if recovery timeout has passed
            if (datetime.now() - self.last_failure_time).seconds > self.recovery_timeout:
                self.state = "half-open"
                return False
            return True
        
        return False
    
    def record_failure(self):
        """Record a failure"""
        self.failure_count += 1
        self.last_failure_time = datetime.now()
        
        if self.failure_count >= self.failure_threshold:
            self.state = "open"
            print(f"[CircuitBreaker] Opened after {self.failure_count} failures")
    
    def record_success(self):
        """Record a success"""
        if self.state == "half-open":
            self.state = "closed"
            self.failure_count = 0
            print(f"[CircuitBreaker] Closed after successful recovery")

```

#### 4.4.2 Consensus and Conflict Resolution

```python
class ConflictResolver:
    """Resolves conflicts between agent findings"""
    
    async def resolve_hypothesis_conflicts(
        self,
        hypotheses: List[Hypothesis]
    ) -> List[Hypothesis]:
        """Resolve conflicts between competing hypotheses"""
        
        # Group hypotheses by root cause category
        grouped = self._group_by_category(hypotheses)
        
        resolved = []
        for category, group in grouped.items():
            if len(group) == 1:
                # No conflict
                resolved.append(group[0])
            else:
                # Multiple hypotheses in same category - need resolution
                resolution = await self._resolve_group_conflict(group)
                resolved.append(resolution)
        
        return resolved
    
    async def _resolve_group_conflict(
        self,
        hypothesis_group: List[Hypothesis]
    ) -> Hypothesis:
        """Resolve conflict within a hypothesis group"""
        
        # Strategy 1: Weighted voting based on agent expertise
        if self._can_use_expertise_voting(hypothesis_group):
            return self._expertise_weighted_vote(hypothesis_group)
        
        # Strategy 2: Evidence-based resolution
        if self._have_sufficient_evidence(hypothesis_group):
            return self._evidence_based_resolution(hypothesis_group)
        
        # Strategy 3: Statistical consensus
        if len(hypothesis_group) >= 3:
            return self._statistical_consensus(hypothesis_group)
        
        # Fallback: Highest confidence
        return max(hypothesis_group, key=lambda h: h.confidence)
    
    def _expertise_weighted_vote(
        self,
        hypotheses: List[Hypothesis]
    ) -> Hypothesis:
        """Vote weighted by agent expertise"""
        
        votes = {}
        for hypothesis in hypotheses:
            # Get agent expertise weight for this category
            weight = self._get_expertise_weight(
                hypothesis.generated_by,
                hypothesis.category
            )
            
            key = hypothesis.root_cause
            if key not in votes:
                votes[key] = 0
            votes[key] += weight * hypothesis.confidence
        
        # Select highest voted root cause
        winning_cause = max(votes.items(), key=lambda x: x[1])[0]
        
        # Return hypothesis with winning root cause
        return next(h for h in hypotheses if h.root_cause == winning_cause)

```

---

**END OF PART 4**

This completes the knowledge integration, learning system, and multi-agent coordination covering:
- External knowledge source integration (GitHub, Confluence, Slack)
- Knowledge caching and semantic search
- Pattern recognition and learning from incidents
- Human feedback integration
- Multi-agent coordination protocols (hierarchical, blackboard, market-based)
- Inter-agent communication patterns
- Failure handling and recovery strategies
- Consensus building and conflict resolution

---

## Part 5: Production Deployment, Monitoring, and Optimization

### 5.1 Production Deployment Architecture

A phased rollout strategy with comprehensive monitoring ensures safe deployment to production.

#### 5.1.1 Deployment Pipeline

```python
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from enum import Enum
import asyncio
import yaml

class DeploymentEnvironment(Enum):
    """Deployment environments with increasing scope"""
    SANDBOX = "sandbox"  # Developer testing
    STAGING = "staging"  # Pre-production validation
    CANARY = "canary"   # Limited production (5% traffic)
    SHADOW = "shadow"   # Parallel non-impacting run
    PRODUCTION = "production"  # Full production

@dataclass
class DeploymentConfig:
    """Production deployment configuration"""
    environment: DeploymentEnvironment
    
    # Resource limits
    max_agents_per_incident: int = 10
    max_cost_per_incident: float = 10.0  # USD
    max_investigation_time: int = 300  # seconds
    
    # Safety controls
    require_human_approval: bool = True
    auto_remediation_enabled: bool = False
    allowed_tools: List[str] = None
    blocked_actions: List[str] = None
    
    # Rollout configuration
    traffic_percentage: float = 100.0
    incident_type_whitelist: List[str] = None
    severity_threshold: str = "low"  # low, medium, high, critical
    
    # Monitoring
    metrics_enabled: bool = True
    trace_sampling_rate: float = 1.0
    log_level: str = "info"
    
    # Feature flags
    features: Dict[str, bool] = None

class ProductionDeployment:
    """Manages production deployment of COMPASS"""
    
    def __init__(self, config_path: str):
        self.config = self._load_config(config_path)
        self.health_checker = HealthChecker()
        self.feature_flags = FeatureFlagManager()
        self.deployment_state = "inactive"
        
    def _load_config(self, path: str) -> DeploymentConfig:
        """Load deployment configuration from YAML"""
        with open(path, 'r') as f:
            data = yaml.safe_load(f)
        return DeploymentConfig(**data)
    
    async def deploy(self, environment: DeploymentEnvironment):
        """Deploy to specified environment with safety checks"""
        
        print(f"[Deploy] Starting deployment to {environment.value}")
        
        # Pre-deployment checks
        if not await self._pre_deployment_checks(environment):
            raise Exception("Pre-deployment checks failed")
        
        # Update configuration for environment
        self.config.environment = environment
        self._apply_environment_limits(environment)
        
        # Initialize components
        await self._initialize_components()
        
        # Start with shadow mode if production
        if environment == DeploymentEnvironment.PRODUCTION:
            await self._shadow_mode_validation()
        
        # Progressive rollout
        await self._progressive_rollout(environment)
        
        # Post-deployment validation
        if not await self._post_deployment_validation():
            await self.rollback()
            raise Exception("Post-deployment validation failed")
        
        self.deployment_state = "active"
        print(f"[Deploy] Successfully deployed to {environment.value}")
    
    async def _pre_deployment_checks(self, environment: DeploymentEnvironment) -> bool:
        """Run pre-deployment safety checks"""
        
        checks = []
        
        # Check system health
        checks.append(("System Health", await self.health_checker.check_system_health()))
        
        # Check dependencies
        checks.append(("Dependencies", await self._check_dependencies()))
        
        # Check resource availability
        checks.append(("Resources", await self._check_resources()))
        
        # Check previous deployment success rate
        if environment in [DeploymentEnvironment.CANARY, DeploymentEnvironment.PRODUCTION]:
            checks.append(("History", await self._check_deployment_history()))
        
        # Validate configuration
        checks.append(("Config", self._validate_configuration()))
        
        # Run test suite
        checks.append(("Tests", await self._run_deployment_tests()))
        
        # Check for ongoing incidents
        if environment == DeploymentEnvironment.PRODUCTION:
            checks.append(("Incidents", await self._check_ongoing_incidents()))
        
        # Print results
        for check_name, passed in checks:
            status = "âœ“" if passed else "âœ—"
            print(f"[Deploy] {status} {check_name}")
        
        return all(passed for _, passed in checks)
    
    async def _progressive_rollout(self, environment: DeploymentEnvironment):
        """Progressive rollout with monitoring"""
        
        if environment == DeploymentEnvironment.PRODUCTION:
            # Start with 1% traffic
            rollout_stages = [1, 5, 10, 25, 50, 100]
        elif environment == DeploymentEnvironment.CANARY:
            rollout_stages = [5, 10, 25]
        else:
            rollout_stages = [100]  # Full rollout for non-production
        
        for percentage in rollout_stages:
            print(f"[Deploy] Rolling out to {percentage}% of traffic")
            
            self.config.traffic_percentage = percentage
            await self._update_load_balancer(percentage)
            
            # Monitor for issues
            monitoring_duration = 300 if environment == DeploymentEnvironment.PRODUCTION else 60
            issues = await self._monitor_rollout(monitoring_duration)
            
            if issues:
                print(f"[Deploy] Issues detected at {percentage}%: {issues}")
                await self.rollback()
                raise Exception(f"Rollout failed at {percentage}%")
            
            print(f"[Deploy] {percentage}% rollout successful")
    
    async def _shadow_mode_validation(self, duration_seconds: int = 600):
        """Run in shadow mode to validate without impact"""
        
        print(f"[Deploy] Starting shadow mode validation ({duration_seconds}s)")
        
        self.config.environment = DeploymentEnvironment.SHADOW
        shadow_results = {
            "investigations_shadowed": 0,
            "differences_found": 0,
            "errors": [],
            "performance_metrics": {}
        }
        
        start_time = asyncio.get_event_loop().time()
        
        while asyncio.get_event_loop().time() - start_time < duration_seconds:
            # Get next production incident
            incident = await self._get_next_incident()
            
            if incident:
                # Run shadow investigation
                shadow_result = await self._run_shadow_investigation(incident)
                shadow_results["investigations_shadowed"] += 1
                
                # Compare with production result
                if shadow_result.differs_from_production:
                    shadow_results["differences_found"] += 1
                
                # Track metrics
                self._update_shadow_metrics(shadow_results, shadow_result)
            
            await asyncio.sleep(1)
        
        # Validate shadow results
        if shadow_results["differences_found"] / max(shadow_results["investigations_shadowed"], 1) > 0.1:
            raise Exception(f"Shadow mode validation failed: too many differences")
        
        print(f"[Deploy] Shadow mode validation passed: {shadow_results}")

```

#### 5.1.2 Infrastructure as Code

```python
class InfrastructureProvisioner:
    """Provisions infrastructure for COMPASS deployment"""
    
    def __init__(self):
        self.terraform_config = self._generate_terraform()
        self.kubernetes_manifests = self._generate_k8s_manifests()
        
    def _generate_terraform(self) -> str:
        """Generate Terraform configuration"""
        
        return """
# COMPASS Infrastructure - Production

terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
    kubernetes = {
      source  = "hashicorp/kubernetes"
      version = "~> 2.0"
    }
  }
}

# EKS Cluster for COMPASS
resource "aws_eks_cluster" "compass" {
  name     = "compass-production"
  role_arn = aws_iam_role.compass_cluster.arn

  vpc_config {
    subnet_ids = var.private_subnet_ids
    
    endpoint_private_access = true
    endpoint_public_access  = false
    
    security_group_ids = [aws_security_group.compass_cluster.id]
  }

  encryption_config {
    provider {
      key_arn = aws_kms_key.compass.arn
    }
    resources = ["secrets"]
  }

  enabled_cluster_log_types = [
    "api", "audit", "authenticator", "controllerManager", "scheduler"
  ]
}

# Node groups for different agent types
resource "aws_eks_node_group" "orchestrator" {
  cluster_name    = aws_eks_cluster.compass.name
  node_group_name = "compass-orchestrator"
  node_role_arn   = aws_iam_role.compass_node.arn
  subnet_ids      = var.private_subnet_ids

  scaling_config {
    desired_size = 2
    max_size     = 4
    min_size     = 2
  }

  instance_types = ["m6i.xlarge"]  # 4 vCPU, 16 GB RAM
  
  labels = {
    "compass/tier" = "orchestrator"
    "compass/role" = "control"
  }

  taints {
    key    = "compass/orchestrator"
    value  = "true"
    effect = "NO_SCHEDULE"
  }
}

resource "aws_eks_node_group" "worker" {
  cluster_name    = aws_eks_cluster.compass.name
  node_group_name = "compass-worker"
  node_role_arn   = aws_iam_role.compass_node.arn
  subnet_ids      = var.private_subnet_ids

  scaling_config {
    desired_size = 5
    max_size     = 20
    min_size     = 3
  }

  instance_types = ["m6i.large"]  # 2 vCPU, 8 GB RAM
  
  labels = {
    "compass/tier" = "worker"
    "compass/role" = "compute"
  }
}

# Redis for state management
resource "aws_elasticache_replication_group" "compass_redis" {
  replication_group_id       = "compass-redis"
  description               = "Redis for COMPASS state and caching"
  node_type                = "cache.r6g.large"
  number_cache_clusters    = 2
  automatic_failover_enabled = true
  multi_az_enabled          = true

  subnet_group_name = aws_elasticache_subnet_group.compass.name
  security_group_ids = [aws_security_group.compass_redis.id]

  at_rest_encryption_enabled = true
  transit_encryption_enabled = true
  auth_token                = random_password.redis_auth.result

  snapshot_retention_limit = 7
  snapshot_window          = "03:00-05:00"
}

# S3 for artifact storage
resource "aws_s3_bucket" "compass_artifacts" {
  bucket = "compass-artifacts-${var.environment}"

  tags = {
    Environment = var.environment
    Purpose     = "Investigation artifacts and logs"
  }
}

resource "aws_s3_bucket_versioning" "compass_artifacts" {
  bucket = aws_s3_bucket.compass_artifacts.id
  versioning_configuration {
    status = "Enabled"
  }
}

resource "aws_s3_bucket_encryption" "compass_artifacts" {
  bucket = aws_s3_bucket.compass_artifacts.id

  rule {
    apply_server_side_encryption_by_default {
      kms_master_key_id = aws_kms_key.compass.arn
      sse_algorithm     = "aws:kms"
    }
  }
}

# DynamoDB for pattern storage
resource "aws_dynamodb_table" "compass_patterns" {
  name           = "compass-incident-patterns"
  billing_mode   = "PAY_PER_REQUEST"
  hash_key       = "pattern_id"
  range_key      = "version"

  attribute {
    name = "pattern_id"
    type = "S"
  }

  attribute {
    name = "version"
    type = "N"
  }

  attribute {
    name = "incident_type"
    type = "S"
  }

  global_secondary_index {
    name            = "IncidentTypeIndex"
    hash_key        = "incident_type"
    projection_type = "ALL"
  }

  point_in_time_recovery {
    enabled = true
  }

  server_side_encryption {
    enabled     = true
    kms_key_arn = aws_kms_key.compass.arn
  }
}
"""
    
    def _generate_k8s_manifests(self) -> Dict[str, str]:
        """Generate Kubernetes manifests"""
        
        manifests = {}
        
        # Namespace and RBAC
        manifests["00-namespace.yaml"] = """
apiVersion: v1
kind: Namespace
metadata:
  name: compass
  labels:
    name: compass
    environment: production
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: compass-orchestrator
  namespace: compass
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: compass-orchestrator
  namespace: compass
rules:
- apiGroups: [""]
  resources: ["pods", "services", "configmaps", "secrets"]
  verbs: ["get", "list", "watch", "create", "update", "patch"]
- apiGroups: ["batch"]
  resources: ["jobs"]
  verbs: ["get", "list", "watch", "create", "delete"]
"""

        # Orchestrator Deployment
        manifests["10-orchestrator.yaml"] = """
apiVersion: apps/v1
kind: Deployment
metadata:
  name: compass-orchestrator
  namespace: compass
spec:
  replicas: 2
  selector:
    matchLabels:
      app: compass-orchestrator
  template:
    metadata:
      labels:
        app: compass-orchestrator
        tier: orchestrator
    spec:
      serviceAccountName: compass-orchestrator
      nodeSelector:
        compass/tier: orchestrator
      tolerations:
      - key: compass/orchestrator
        operator: Equal
        value: "true"
        effect: NoSchedule
      containers:
      - name: orchestrator
        image: compass/orchestrator:latest
        ports:
        - containerPort: 8080
          name: http
        - containerPort: 9090
          name: metrics
        env:
        - name: ENVIRONMENT
          value: production
        - name: REDIS_URL
          valueFrom:
            secretKeyRef:
              name: compass-redis
              key: url
        - name: MAX_WORKERS
          value: "10"
        - name: MAX_COST_PER_INCIDENT
          value: "10.0"
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 5
"""

        # Worker Pool
        manifests["20-worker-pool.yaml"] = """
apiVersion: apps/v1
kind: Deployment
metadata:
  name: compass-worker-pool
  namespace: compass
spec:
  replicas: 10
  selector:
    matchLabels:
      app: compass-worker
  template:
    metadata:
      labels:
        app: compass-worker
        tier: worker
    spec:
      nodeSelector:
        compass/tier: worker
      containers:
      - name: worker
        image: compass/worker:latest
        env:
        - name: WORKER_TYPE
          value: "general"
        - name: REDIS_URL
          valueFrom:
            secretKeyRef:
              name: compass-redis
              key: url
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
---
# Specialized workers for different agent types
apiVersion: apps/v1
kind: Deployment
metadata:
  name: compass-database-workers
  namespace: compass
spec:
  replicas: 3
  selector:
    matchLabels:
      app: compass-worker-database
  template:
    metadata:
      labels:
        app: compass-worker-database
        tier: worker
        specialty: database
    spec:
      containers:
      - name: worker
        image: compass/worker:latest
        env:
        - name: WORKER_TYPE
          value: "database"
        - name: SPECIALIZATION
          value: "postgresql,mysql,mongodb"
"""

        # Monitoring
        manifests["30-monitoring.yaml"] = """
apiVersion: v1
kind: Service
metadata:
  name: compass-metrics
  namespace: compass
  labels:
    app: compass
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "9090"
spec:
  ports:
  - port: 9090
    name: metrics
  selector:
    tier: orchestrator
---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: compass-metrics
  namespace: compass
spec:
  selector:
    matchLabels:
      app: compass
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics
"""

        return manifests

```

### 5.2 Performance Monitoring and Observability

Comprehensive monitoring ensures system health and enables optimization.

#### 5.2.1 Metrics Collection

```python
from prometheus_client import Counter, Histogram, Gauge, Summary
import time

class MetricsCollector:
    """Collects and exposes metrics for monitoring"""
    
    def __init__(self):
        # Investigation metrics
        self.investigations_total = Counter(
            'compass_investigations_total',
            'Total number of investigations',
            ['incident_type', 'severity', 'outcome']
        )
        
        self.investigation_duration = Histogram(
            'compass_investigation_duration_seconds',
            'Investigation duration in seconds',
            ['incident_type'],
            buckets=[10, 30, 60, 120, 300, 600, 1800]
        )
        
        self.hypothesis_accuracy = Gauge(
            'compass_hypothesis_accuracy',
            'Hypothesis accuracy rate',
            ['agent_type', 'hypothesis_type']
        )
        
        # Agent metrics
        self.agents_active = Gauge(
            'compass_agents_active',
            'Number of active agents',
            ['agent_type']
        )
        
        self.agent_task_duration = Histogram(
            'compass_agent_task_duration_seconds',
            'Agent task execution duration',
            ['agent_type', 'task_type'],
            buckets=[1, 5, 10, 30, 60, 120]
        )
        
        self.agent_failures = Counter(
            'compass_agent_failures_total',
            'Total agent failures',
            ['agent_type', 'failure_type']
        )
        
        # Cost metrics
        self.llm_token_usage = Counter(
            'compass_llm_tokens_total',
            'Total LLM tokens used',
            ['model', 'token_type']  # input/output
        )
        
        self.investigation_cost = Histogram(
            'compass_investigation_cost_usd',
            'Investigation cost in USD',
            ['incident_type'],
            buckets=[0.01, 0.05, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0]
        )
        
        # Resource metrics
        self.redis_operations = Counter(
            'compass_redis_operations_total',
            'Redis operations',
            ['operation', 'status']
        )
        
        self.external_api_calls = Counter(
            'compass_external_api_calls_total',
            'External API calls',
            ['api', 'status']
        )
        
        # Quality metrics
        self.human_feedback_score = Summary(
            'compass_human_feedback_score',
            'Human feedback scores',
            ['feedback_type']
        )
        
        self.mttr_reduction = Gauge(
            'compass_mttr_reduction_percentage',
            'MTTR reduction compared to baseline'
        )
    
    def record_investigation(
        self,
        incident_type: str,
        severity: str,
        duration_seconds: float,
        cost_usd: float,
        outcome: str
    ):
        """Record investigation metrics"""
        
        self.investigations_total.labels(
            incident_type=incident_type,
            severity=severity,
            outcome=outcome
        ).inc()
        
        self.investigation_duration.labels(
            incident_type=incident_type
        ).observe(duration_seconds)
        
        self.investigation_cost.labels(
            incident_type=incident_type
        ).observe(cost_usd)
    
    def record_agent_task(
        self,
        agent_type: str,
        task_type: str,
        duration_seconds: float,
        success: bool
    ):
        """Record agent task execution"""
        
        self.agent_task_duration.labels(
            agent_type=agent_type,
            task_type=task_type
        ).observe(duration_seconds)
        
        if not success:
            self.agent_failures.labels(
                agent_type=agent_type,
                failure_type="task_failure"
            ).inc()
    
    def record_llm_usage(
        self,
        model: str,
        input_tokens: int,
        output_tokens: int
    ):
        """Record LLM token usage"""
        
        self.llm_token_usage.labels(
            model=model,
            token_type="input"
        ).inc(input_tokens)
        
        self.llm_token_usage.labels(
            model=model,
            token_type="output"
        ).inc(output_tokens)

class TracingManager:
    """Manages distributed tracing for investigations"""
    
    def __init__(self, jaeger_endpoint: str):
        from opentelemetry import trace
        from opentelemetry.exporter.jaeger import JaegerExporter
        from opentelemetry.sdk.trace import TracerProvider
        from opentelemetry.sdk.trace.export import BatchSpanProcessor
        
        # Initialize tracer
        trace.set_tracer_provider(TracerProvider())
        self.tracer = trace.get_tracer("compass")
        
        # Configure Jaeger exporter
        jaeger_exporter = JaegerExporter(
            agent_host_name=jaeger_endpoint,
            agent_port=6831,
        )
        
        span_processor = BatchSpanProcessor(jaeger_exporter)
        trace.get_tracer_provider().add_span_processor(span_processor)
    
    def start_investigation_trace(self, incident_id: str) -> Any:
        """Start trace for new investigation"""
        
        return self.tracer.start_as_current_span(
            f"investigation_{incident_id}",
            attributes={
                "incident.id": incident_id,
                "service.name": "compass",
                "span.kind": "server"
            }
        )
    
    def trace_agent_task(self, agent_id: str, task_type: str) -> Any:
        """Trace individual agent task"""
        
        return self.tracer.start_as_current_span(
            f"agent_task_{task_type}",
            attributes={
                "agent.id": agent_id,
                "task.type": task_type,
                "span.kind": "internal"
            }
        )

```

#### 5.2.2 Dashboards and Alerts

```python
class DashboardGenerator:
    """Generates monitoring dashboards"""
    
    def generate_grafana_dashboard(self) -> Dict:
        """Generate Grafana dashboard JSON"""
        
        return {
            "dashboard": {
                "title": "COMPASS Operations Dashboard",
                "timezone": "browser",
                "panels": [
                    {
                        "id": 1,
                        "title": "Investigation Rate",
                        "type": "graph",
                        "targets": [{
                            "expr": "rate(compass_investigations_total[5m])",
                            "legendFormat": "{{incident_type}}"
                        }],
                        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0}
                    },
                    {
                        "id": 2,
                        "title": "Investigation Duration (p95)",
                        "type": "graph",
                        "targets": [{
                            "expr": "histogram_quantile(0.95, compass_investigation_duration_seconds)",
                            "legendFormat": "p95 Duration"
                        }],
                        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0}
                    },
                    {
                        "id": 3,
                        "title": "Cost per Investigation",
                        "type": "graph",
                        "targets": [{
                            "expr": "compass_investigation_cost_usd",
                            "legendFormat": "{{incident_type}}"
                        }],
                        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 8}
                    },
                    {
                        "id": 4,
                        "title": "Active Agents",
                        "type": "graph",
                        "targets": [{
                            "expr": "compass_agents_active",
                            "legendFormat": "{{agent_type}}"
                        }],
                        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 8}
                    },
                    {
                        "id": 5,
                        "title": "LLM Token Usage Rate",
                        "type": "graph",
                        "targets": [{
                            "expr": "rate(compass_llm_tokens_total[5m])",
                            "legendFormat": "{{model}} - {{token_type}}"
                        }],
                        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 16}
                    },
                    {
                        "id": 6,
                        "title": "Agent Failure Rate",
                        "type": "graph",
                        "targets": [{
                            "expr": "rate(compass_agent_failures_total[5m])",
                            "legendFormat": "{{agent_type}} - {{failure_type}}"
                        }],
                        "alert": {
                            "conditions": [{
                                "evaluator": {"params": [0.1], "type": "gt"},
                                "operator": {"type": "and"},
                                "query": {"params": ["A", "5m", "now"]},
                                "reducer": {"params": [], "type": "avg"},
                                "type": "query"
                            }]
                        },
                        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 16}
                    }
                ]
            }
        }
    
    def generate_alert_rules(self) -> List[Dict]:
        """Generate Prometheus alert rules"""
        
        return [
            {
                "alert": "HighInvestigationFailureRate",
                "expr": "rate(compass_investigations_total{outcome='failure'}[5m]) > 0.1",
                "for": "5m",
                "labels": {
                    "severity": "warning",
                    "component": "compass"
                },
                "annotations": {
                    "summary": "High investigation failure rate",
                    "description": "{{ $value | humanizePercentage }} of investigations are failing"
                }
            },
            {
                "alert": "InvestigationCostExceeded",
                "expr": "compass_investigation_cost_usd > 10",
                "for": "1m",
                "labels": {
                    "severity": "warning",
                    "component": "compass"
                },
                "annotations": {
                    "summary": "Investigation cost exceeded threshold",
                    "description": "Investigation cost ${{ $value }} exceeds $10 limit"
                }
            },
            {
                "alert": "AgentPoolExhausted",
                "expr": "compass_agents_active / compass_agents_total > 0.9",
                "for": "5m",
                "labels": {
                    "severity": "critical",
                    "component": "compass"
                },
                "annotations": {
                    "summary": "Agent pool nearly exhausted",
                    "description": "{{ $value | humanizePercentage }} of agents are active"
                }
            },
            {
                "alert": "HighLLMTokenUsage",
                "expr": "rate(compass_llm_tokens_total[1h]) > 1000000",
                "for": "5m",
                "labels": {
                    "severity": "warning",
                    "component": "compass"
                },
                "annotations": {
                    "summary": "High LLM token usage detected",
                    "description": "Using {{ $value }} tokens per hour"
                }
            }
        ]

```

### 5.3 Cost Optimization

Implementing strategies to minimize operational costs while maintaining performance.

#### 5.3.1 Intelligent Caching

```python
class CostOptimizer:
    """Optimizes costs across the system"""
    
    def __init__(self):
        self.cache_manager = IntelligentCacheManager()
        self.model_router = ModelRouter()
        self.token_optimizer = TokenOptimizer()
        
    async def optimize_llm_request(
        self,
        prompt: str,
        required_capability: str,
        max_cost: float
    ) -> Dict:
        """Optimize LLM request for cost"""
        
        # Check cache first
        cached_response = await self.cache_manager.get_cached_response(
            prompt_hash=hashlib.md5(prompt.encode()).hexdigest()
        )
        
        if cached_response:
            print(f"[Optimizer] Cache hit, saved ${cached_response['saved_cost']:.4f}")
            return cached_response['response']
        
        # Optimize prompt
        optimized_prompt = self.token_optimizer.optimize_prompt(prompt)
        
        # Select cheapest capable model
        model = self.model_router.select_model(
            required_capability=required_capability,
            max_cost=max_cost,
            prompt_length=len(optimized_prompt)
        )
        
        # Make request with optimized settings
        response = await self._make_llm_request(
            model=model,
            prompt=optimized_prompt,
            settings=self._get_optimized_settings(model)
        )
        
        # Cache response
        await self.cache_manager.cache_response(
            prompt_hash=hashlib.md5(prompt.encode()).hexdigest(),
            response=response,
            ttl_seconds=3600
        )
        
        return response
    
    def _get_optimized_settings(self, model: str) -> Dict:
        """Get optimized settings for model"""
        
        return {
            "temperature": 0,  # Deterministic for caching
            "max_tokens": 500,  # Limit output length
            "stream": False,
            "presence_penalty": 0,
            "frequency_penalty": 0
        }

class ModelRouter:
    """Routes requests to appropriate models based on requirements"""
    
    def __init__(self):
        self.model_capabilities = {
            "gpt-4o-mini": {
                "cost_per_1k_input": 0.00015,
                "cost_per_1k_output": 0.0006,
                "capabilities": ["basic_reasoning", "classification", "extraction"],
                "max_context": 128000
            },
            "gpt-4o": {
                "cost_per_1k_input": 0.0025,
                "cost_per_1k_output": 0.01,
                "capabilities": ["complex_reasoning", "analysis", "synthesis"],
                "max_context": 128000
            },
            "claude-3-haiku": {
                "cost_per_1k_input": 0.00025,
                "cost_per_1k_output": 0.00125,
                "capabilities": ["basic_reasoning", "fast_response"],
                "max_context": 200000
            },
            "claude-3-sonnet": {
                "cost_per_1k_input": 0.003,
                "cost_per_1k_output": 0.015,
                "capabilities": ["complex_reasoning", "nuanced_analysis"],
                "max_context": 200000
            }
        }
    
    def select_model(
        self,
        required_capability: str,
        max_cost: float,
        prompt_length: int
    ) -> str:
        """Select cheapest model that meets requirements"""
        
        eligible_models = []
        
        for model, specs in self.model_capabilities.items():
            # Check capability
            if required_capability not in specs["capabilities"]:
                continue
            
            # Check context window
            if prompt_length > specs["max_context"]:
                continue
            
            # Estimate cost
            estimated_cost = (
                (prompt_length / 1000) * specs["cost_per_1k_input"] +
                (500 / 1000) * specs["cost_per_1k_output"]  # Assume 500 token output
            )
            
            if estimated_cost <= max_cost:
                eligible_models.append((model, estimated_cost))
        
        if not eligible_models:
            raise Exception(f"No model available within budget ${max_cost}")
        
        # Return cheapest eligible model
        return min(eligible_models, key=lambda x: x[1])[0]

class TokenOptimizer:
    """Optimizes prompts to reduce token usage"""
    
    def optimize_prompt(self, prompt: str) -> str:
        """Optimize prompt for token efficiency"""
        
        optimizations = []
        
        # Remove redundant whitespace
        optimized = " ".join(prompt.split())
        
        # Use abbreviations for common terms
        abbreviations = {
            "investigation": "inv",
            "hypothesis": "hyp",
            "observation": "obs",
            "root cause": "RC",
            "mean time to resolution": "MTTR"
        }
        
        for full, abbr in abbreviations.items():
            optimized = optimized.replace(full, abbr)
        
        # Remove unnecessary examples if present
        if "For example:" in optimized:
            # Keep only first example
            parts = optimized.split("For example:")
            if len(parts) > 2:
                optimized = parts[0] + "For example:" + parts[1]
        
        # Compress JSON if present
        import json
        import re
        json_pattern = r'\{[^{}]*\}'
        
        for match in re.finditer(json_pattern, optimized):
            try:
                json_data = json.loads(match.group())
                compressed = json.dumps(json_data, separators=(',', ':'))
                optimized = optimized.replace(match.group(), compressed)
            except:
                pass
        
        return optimized

```

### 5.4 Security Implementation

Security measures to protect the system and prevent abuse.

#### 5.4.1 Security Controls

```python
class SecurityManager:
    """Manages security controls for COMPASS"""
    
    def __init__(self):
        self.rate_limiter = RateLimiter()
        self.auth_manager = AuthenticationManager()
        self.audit_logger = AuditLogger()
        self.prompt_validator = PromptValidator()
        
    async def validate_request(
        self,
        request: InvestigationRequest,
        user_context: UserContext
    ) -> ValidationResult:
        """Validate investigation request for security"""
        
        validations = []
        
        # Authentication and authorization
        auth_result = await self.auth_manager.validate_user(user_context)
        if not auth_result.is_valid:
            return ValidationResult(
                is_valid=False,
                reason="Authentication failed",
                details=auth_result.details
            )
        
        # Rate limiting
        if not self.rate_limiter.check_limit(user_context.user_id):
            return ValidationResult(
                is_valid=False,
                reason="Rate limit exceeded",
                details={"limit": "100 requests per hour"}
            )
        
        # Input validation
        if not self._validate_input(request):
            return ValidationResult(
                is_valid=False,
                reason="Invalid input",
                details={"issue": "Malformed request data"}
            )
        
        # Prompt injection detection
        injection_check = self.prompt_validator.check_injection(
            request.description
        )
        if injection_check.is_injection:
            self.audit_logger.log_security_event(
                event_type="prompt_injection_attempt",
                user_id=user_context.user_id,
                details=injection_check.details
            )
            return ValidationResult(
                is_valid=False,
                reason="Security violation detected",
                details={"type": "prompt_injection"}
            )
        
        # Resource access validation
        if not await self._validate_resource_access(request, user_context):
            return ValidationResult(
                is_valid=False,
                reason="Insufficient permissions",
                details={"required": "read access to specified resources"}
            )
        
        return ValidationResult(is_valid=True)
    
    async def _validate_resource_access(
        self,
        request: InvestigationRequest,
        user_context: UserContext
    ) -> bool:
        """Validate user has access to requested resources"""
        
        # Check service access
        for service in request.affected_services:
            if not await self.auth_manager.check_service_access(
                user_context.user_id,
                service
            ):
                return False
        
        # Check data access levels
        if request.include_sensitive_data:
            if "sensitive_data_access" not in user_context.permissions:
                return False
        
        return True

class PromptValidator:
    """Validates prompts for injection attacks"""
    
    def __init__(self):
        self.injection_patterns = [
            r"ignore previous instructions",
            r"disregard all prior",
            r"forget everything",
            r"new instructions:",
            r"system prompt",
            r"admin mode",
            r"sudo",
            r"bypass security"
        ]
        
    def check_injection(self, text: str) -> InjectionCheckResult:
        """Check for prompt injection attempts"""
        
        lower_text = text.lower()
        
        # Check for known injection patterns
        for pattern in self.injection_patterns:
            if re.search(pattern, lower_text):
                return InjectionCheckResult(
                    is_injection=True,
                    confidence=0.9,
                    details={"pattern_matched": pattern}
                )
        
        # Check for suspicious token sequences
        suspicious_tokens = self._check_suspicious_tokens(text)
        if suspicious_tokens:
            return InjectionCheckResult(
                is_injection=True,
                confidence=0.7,
                details={"suspicious_tokens": suspicious_tokens}
            )
        
        # Check for encoding tricks
        if self._has_encoding_tricks(text):
            return InjectionCheckResult(
                is_injection=True,
                confidence=0.8,
                details={"issue": "encoding manipulation detected"}
            )
        
        return InjectionCheckResult(is_injection=False)
    
    def _check_suspicious_tokens(self, text: str) -> List[str]:
        """Check for suspicious token sequences"""
        
        suspicious = []
        
        # Check for control characters
        if any(ord(c) < 32 and c not in '\n\r\t' for c in text):
            suspicious.append("control_characters")
        
        # Check for excessive special characters
        special_char_ratio = len(re.findall(r'[^a-zA-Z0-9\s]', text)) / max(len(text), 1)
        if special_char_ratio > 0.3:
            suspicious.append("excessive_special_chars")
        
        return suspicious

class AuditLogger:
    """Logs security and compliance events"""
    
    def __init__(self, storage_backend):
        self.storage = storage_backend
        
    async def log_security_event(
        self,
        event_type: str,
        user_id: str,
        details: Dict
    ):
        """Log security event for audit trail"""
        
        event = {
            "timestamp": datetime.now().isoformat(),
            "event_type": event_type,
            "user_id": user_id,
            "details": details,
            "session_id": self._get_session_id(),
            "ip_address": self._get_client_ip()
        }
        
        # Store in immutable audit log
        await self.storage.append_audit_log(event)
        
        # Alert on critical events
        if event_type in ["prompt_injection_attempt", "unauthorized_access"]:
            await self._send_security_alert(event)

```

### 5.5 Testing and Validation Framework

Comprehensive testing ensures reliability and correctness.

#### 5.5.1 Integration Testing

```python
class IntegrationTestSuite:
    """Integration tests for COMPASS system"""
    
    async def test_end_to_end_investigation(self):
        """Test complete investigation flow"""
        
        # Setup test incident
        test_incident = self._create_test_incident(
            incident_type="database_deadlock",
            severity="high"
        )
        
        # Initialize COMPASS
        compass = await self._initialize_test_compass()
        
        # Run investigation
        investigation = await compass.investigate(test_incident)
        
        # Validate results
        assert investigation.status == "completed"
        assert len(investigation.hypotheses) >= 3
        assert investigation.root_cause is not None
        assert investigation.cost_usd < 5.0
        assert investigation.duration_seconds < 300
        
        # Validate hypothesis quality
        for hypothesis in investigation.hypotheses:
            assert hypothesis.confidence > 0.5
            assert hypothesis.evidence_count > 0
            assert hypothesis.falsifiable
        
        # Validate action plan
        assert len(investigation.recommended_actions) > 0
        for action in investigation.recommended_actions:
            assert action.risk_level in ["low", "medium", "high"]
            assert action.estimated_impact is not None
    
    async def test_agent_coordination(self):
        """Test multi-agent coordination"""
        
        # Create coordinator
        coordinator = AgentCoordinator(CoordinationProtocol.HIERARCHICAL)
        
        # Create test agents
        orchestrator = MockOrchestrator()
        managers = [MockManager(f"manager_{i}") for i in range(3)]
        workers = [MockWorker(f"worker_{i}") for i in range(9)]
        
        # Test coordination
        test_incident = self._create_test_incident()
        investigation = await coordinator.coordinate_investigation(
            test_incident,
            [orchestrator] + managers + workers
        )
        
        # Validate coordination
        assert orchestrator.plan_created
        assert all(m.tasks_received > 0 for m in managers)
        assert all(w.tasks_executed > 0 for w in workers)
        assert investigation.observations_count > 0
    
    async def test_failure_recovery(self):
        """Test failure handling and recovery"""
        
        # Create test scenario with failing agent
        failing_agent = MockFailingAgent(fail_after=3)
        backup_agent = MockWorker("backup")
        
        handler = AgentFailureHandler()
        
        # Test recovery
        task = Task(task_id="test", task_type="analysis")
        
        for i in range(5):
            try:
                result = await failing_agent.execute_task(task)
            except Exception as e:
                recovery = await handler.handle_agent_failure(
                    failing_agent.id,
                    task,
                    e
                )
                
                if recovery.action_type == "reassign":
                    result = await backup_agent.execute_task(task)
                    break
        
        assert result is not None
        assert handler.circuit_breakers[failing_agent.id].is_open()

class LoadTestSuite:
    """Load testing for COMPASS"""
    
    async def test_concurrent_investigations(self):
        """Test system under concurrent load"""
        
        compass = await self._initialize_production_compass()
        
        # Create concurrent investigations
        num_concurrent = 50
        incidents = [
            self._create_random_incident()
            for _ in range(num_concurrent)
        ]
        
        # Run investigations concurrently
        start_time = time.time()
        
        tasks = [
            compass.investigate(incident)
            for incident in incidents
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        end_time = time.time()
        duration = end_time - start_time
        
        # Validate performance
        successful = [r for r in results if not isinstance(r, Exception)]
        
        assert len(successful) / len(results) > 0.95  # 95% success rate
        assert duration < 120  # Complete within 2 minutes
        
        # Validate resource usage
        avg_cost = sum(r.cost_usd for r in successful) / len(successful)
        assert avg_cost < 5.0  # Average cost under $5
        
        print(f"Load test completed: {len(successful)}/{num_concurrent} successful")
        print(f"Duration: {duration:.2f}s")
        print(f"Average cost: ${avg_cost:.2f}")

```

### 5.6 Operational Runbooks

Standardized procedures for operating COMPASS in production.

#### 5.6.1 Incident Response Runbook

```python
class OperationalRunbooks:
    """Operational procedures for COMPASS"""
    
    @staticmethod
    def get_runbook(scenario: str) -> str:
        """Get runbook for operational scenario"""
        
        runbooks = {
            "high_cost_investigation": """
# High Cost Investigation Runbook

## Alert: Investigation cost exceeds threshold ($10)

### Immediate Actions:
1. Check investigation dashboard for incident_id
2. Verify if investigation is still active:
   ```bash
   kubectl get pods -n compass -l investigation_id=<ID>
   ```

### If Active:
1. Check investigation complexity:
   ```bash
   kubectl logs -n compass compass-orchestrator-<POD> | grep <incident_id>
   ```

2. If runaway investigation (>20 agents or >30 minutes):
   - Terminate investigation:
     ```bash
     kubectl exec -n compass compass-orchestrator-<POD> -- \
       compass-cli terminate-investigation <incident_id>
     ```

3. If legitimate complex investigation:
   - Monitor progress
   - Notify on-call if cost exceeds $20

### Root Cause Analysis:
1. Review investigation trace in Jaeger
2. Check for:
   - Infinite loops in agent coordination
   - Excessive LLM calls
   - Large context windows
3. File bug report if systemic issue

### Prevention:
- Update cost limits in config
- Add incident type to monitoring
""",
            
            "agent_pool_exhaustion": """
# Agent Pool Exhaustion Runbook

## Alert: >90% of agent pool in use

### Immediate Actions:
1. Check current agent utilization:
   ```bash
   kubectl top pods -n compass | grep compass-worker
   ```

2. Scale worker pool:
   ```bash
   kubectl scale deployment compass-worker-pool --replicas=20 -n compass
   ```

### Investigation:
1. Check for stuck investigations:
   ```sql
   SELECT incident_id, started_at, agent_count 
   FROM investigations 
   WHERE status = 'active' 
   AND started_at < NOW() - INTERVAL '30 minutes';
   ```

2. Review agent failure rate:
   ```
   Check Grafana dashboard: COMPASS > Agent Health
   ```

### Recovery:
1. If agents are stuck:
   - Restart worker pods:
     ```bash
     kubectl rollout restart deployment compass-worker-pool -n compass
     ```

2. If legitimate high load:
   - Enable auto-scaling:
     ```bash
     kubectl autoscale deployment compass-worker-pool \
       --min=10 --max=50 --cpu-percent=70 -n compass
     ```

### Follow-up:
- Review capacity planning
- Adjust agent timeout settings
""",
            
            "investigation_failures": """
# Investigation Failure Runbook

## Alert: >10% investigation failure rate

### Triage:
1. Identify failure pattern:
   ```sql
   SELECT incident_type, failure_reason, COUNT(*) 
   FROM investigations 
   WHERE status = 'failed' 
   AND completed_at > NOW() - INTERVAL '1 hour'
   GROUP BY incident_type, failure_reason;
   ```

2. Check system health:
   - Redis connectivity
   - LLM API availability
   - Kubernetes cluster health

### Common Failures:

#### LLM API Errors:
- Check API keys and quotas
- Verify network connectivity
- Switch to backup LLM provider

#### Resource Timeouts:
- Increase timeout settings
- Check database performance
- Review query optimization

#### Agent Coordination Failures:
- Check message bus (Redis)
- Review agent logs for deadlocks
- Restart orchestrator if needed

### Recovery:
1. Retry failed investigations:
   ```bash
   compass-cli retry-failed --last-hour
   ```

2. If systematic issue:
   - Enable fallback mode
   - Route to manual investigation
   - Page on-call engineer

### Prevention:
- Add retry logic for transient failures
- Implement circuit breakers
- Enhance error handling
"""
        }
        
        return runbooks.get(scenario, "No runbook available for scenario")

```

---

**END OF IMPLEMENTATION GUIDE**

## Summary

This completes the comprehensive COMPASS implementation guide covering:

### Part 1: Foundation & OODA Loop Structure
- System architecture and design principles
- Incident classification and routing
- Observe phase implementation with parallel data gathering
- MCP tool integration

### Part 2: Orient & Decide Phases  
- Hypothesis generation and synthesis
- Pattern recognition from observations
- Human decision interface
- Investigation plan creation

### Part 3: Act Phase & State Management
- Systematic hypothesis testing
- Falsification and evidence gathering
- Investigation state machine
- Cost tracking and budget controls

### Part 4: Knowledge & Coordination
- External knowledge integration (GitHub, Confluence, Slack)
- Learning system and pattern recognition
- Multi-agent coordination protocols
- Failure handling and consensus building

### Part 5: Production Operations
- Deployment pipeline and infrastructure
- Comprehensive monitoring and alerting
- Cost optimization strategies
- Security controls and validation
- Operational runbooks

## Key Implementation Takeaways

1. **Start Simple, Scale Gradually**: Begin with single-agent automation, progressively add complexity
2. **Maintain Human Control**: AI augments but doesn't replace human judgment
3. **Cost Management is Critical**: Token usage multiplies with agents - implement strict controls
4. **Observability First**: You can't optimize what you can't measure
5. **Learn from Every Incident**: Continuous improvement through pattern recognition
6. **Security by Design**: Validate inputs, audit actions, implement defense in depth
7. **Test Extensively**: Integration, load, and failure testing prevent production issues
8. **Document Everything**: Clear runbooks enable rapid response

The COMPASS system demonstrates how ICS principles, OODA loop methodology, and modern AI capabilities can combine to create a powerful incident investigation platform that reduces MTTR by 67-90% while maintaining safety, accountability, and cost-effectiveness.