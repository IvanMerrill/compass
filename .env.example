# ============================================================================
# COMPASS Environment Configuration
# ============================================================================
# Copy this file to .env and fill in your actual values
# WARNING: Never commit .env files with real credentials to version control!
# ============================================================================

# ----------------------------------------------------------------------------
# Application Environment
# ----------------------------------------------------------------------------
# Application environment: dev, test, or prod
# Affects logging format (dev=console, prod=JSON) and behavior
ENVIRONMENT=dev

# Logging level: DEBUG, INFO, WARNING, ERROR
# Use DEBUG for development, INFO for production
LOG_LEVEL=INFO

# ----------------------------------------------------------------------------
# Redis Configuration
# ----------------------------------------------------------------------------
# Redis is used for caching, session storage, and agent coordination
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0

# SECURITY WARNING: Keep Redis password secure in production!
# Leave empty for local development without authentication
REDIS_PASSWORD=

# ----------------------------------------------------------------------------
# PostgreSQL Configuration
# ----------------------------------------------------------------------------
# PostgreSQL is used for investigation history and learning data
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=compass
POSTGRES_USER=compass

# SECURITY WARNING: Use strong passwords in production!
# This is a development default only
POSTGRES_PASSWORD=compass_dev

# ----------------------------------------------------------------------------
# LLM Provider Settings
# ----------------------------------------------------------------------------
# SECURITY WARNING: API keys are sensitive credentials!
# Never commit real API keys to version control
# Get keys from: https://platform.openai.com/ and https://console.anthropic.com/

# OpenAI API key for GPT models
OPENAI_API_KEY=sk-your-openai-key-here

# Anthropic API key for Claude models
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here

# Default LLM provider: "openai" or "anthropic"
DEFAULT_LLM_PROVIDER=openai

# Default model for general agent tasks
# OpenAI: gpt-4o-mini, gpt-4, gpt-4-turbo, etc.
# Anthropic: claude-3-haiku-20240307, claude-3-sonnet-20240229, etc.
DEFAULT_MODEL_NAME=gpt-4o-mini

# Model for orchestrator (higher capability recommended)
ORCHESTRATOR_MODEL=gpt-4

# ----------------------------------------------------------------------------
# Investigation Limits
# ----------------------------------------------------------------------------
# Maximum time (in seconds) an investigation can run before timeout
MAX_INVESTIGATION_TIMEOUT_SECONDS=300

# Default cost budget per investigation in USD
# This prevents runaway costs from LLM API calls
DEFAULT_COST_BUDGET_USD=10.0

# Cost budget for critical/high-priority investigations in USD
CRITICAL_COST_BUDGET_USD=20.0

# Maximum number of agents that can run in parallel
# Based on ICS hierarchy (1 orchestrator + 6 agents by default)
MAX_PARALLEL_AGENTS=7

# ----------------------------------------------------------------------------
# Feature Flags
# ----------------------------------------------------------------------------
# Enable learning from investigation outcomes
# When true, successful investigations are stored for future reference
ENABLE_LEARNING=true

# Enable LLM response caching
# Reduces costs and latency by caching identical requests
ENABLE_CACHING=true

# Enable OpenTelemetry distributed tracing
# Provides observability into investigation flows and agent interactions
ENABLE_OBSERVABILITY=true

# ----------------------------------------------------------------------------
# Grafana MCP Server Configuration
# ----------------------------------------------------------------------------
# Grafana MCP server provides access to Prometheus, Mimir, Loki via MCP protocol
GRAFANA_URL=http://localhost:3000
GRAFANA_ADMIN_PASSWORD=admin
GRAFANA_SERVICE_ACCOUNT_TOKEN=your-service-account-token-here

# Grafana Data Source UIDs (find in Grafana UI: Configuration â†’ Data Sources)
PROMETHEUS_DATASOURCE_UID=prometheus
MIMIR_DATASOURCE_UID=mimir
LOKI_DATASOURCE_UID=loki

# Grafana MCP server endpoint (when running via docker-compose)
GRAFANA_MCP_URL=http://localhost:8000

# ----------------------------------------------------------------------------
# Tempo MCP Server Configuration
# ----------------------------------------------------------------------------
# Tempo MCP server provides access to distributed traces via TraceQL
# For production: use your actual Tempo MCP endpoint
TEMPO_MCP_URL=http://localhost:3200/api/mcp

# ----------------------------------------------------------------------------
# Testing Configuration
# ----------------------------------------------------------------------------
# Set to "true" to run integration tests against real MCP servers
# Requires valid Grafana and Tempo credentials
RUN_INTEGRATION_TESTS=false
